import os
import pandas as pd
import glob
from pprint import pprint
import concurrent.futures

"""

Subject
===========

This module provides a class and some initialisation functions designed to be used with a dataset directory that has been created using the preprocess_pre_fastsurfer module. The Subject class is a representation of a single subject in the dataset, and contains paths to the processed files for that subject. The init_subject and init_subject_parallel functions are used to create Subject objects from the dataset directory.

:author: Oscar Lloyd-John

"""

class Subject:

    """
    A class that represents an ADNI (or other) subject. Note that this class effectively represents one instance of an MRI image of a subject and its accompanying processed files. It is not a general representation of a subject, which could have multiple images however it is expected that only one image per subject will be studied because overfitting of a machine learning model is likely otherwise. See "Hippocampal representations for deep learning on Alzheimerâ€™s disease", Sarasua et. al. 2021 for more information.

    Note that this class expects the provided directory to be of the correct structure, and therefore is not intended to be used standalone but to be instantiated using the init_subject or init_subject_parallel functions.

    This class is file path based, meaning it does not store image data in memory. This means the class can be instantiated as many times as needed provided that the directory structure does not change. All file processing in the entire preprocessing_post_fastsurfer module is saved to disk, meaning the Subject class effectively just serves as a collection of pointers.

    Specific brain regions such as the hippocampus are not stored in class variables because there are so many possible regions that it would be unreasonable to store them all. Instead, they can be accessed using the filename directly. See extraction.py for more information.

    Parameters:
    ----------
    :param path: The path to the subject directory
    :type path: os.PathLike[str]
    :param subject_metadata: A dataframe containing metadata for the subject, this will be a single row
    :type subject_metadata: pd.DataFrame

    Attributes (existing before post processing):

    Note that these attributes will always be present as long as the Fastsurfer processing was successful
    ----------
    :ivar path: The path to the top level of the subject directory
    
    :ivar orig_nu: The path to the orig_nu.mgz, which is the intensity normalised 256x256x256 image generated by fastsurfer for use in the parcellation process.
    
    :ivar mask: The path to mask.mgz, which is the 3d brain mask generated by fastsurfer.

    :ivar aparc: The path to the aparc.DKTatlas+aseg.deep.mgz, which is the parcellation file generated by fastsurfer. Note that fastsurfer generates multiple parcellation files, this one was chosen for study.

    :ivar subject_metadata: A dataframe containing metadata for the subject, this will be a single row.

    :ivar aseg_stats: A dataframe containing the values from aseg+DKT.stats, which is the Fastsurfer generated file containing parcellation volumes.

    Attributes (existing after post processing):

    These attributes will be None if the post processing step associated with them has not been performed. They are used to store paths from the other functions in this module.
    ----------
    :ivar brain_aligned: The path to brain_aligned.nii, which is the brain orig_nu image after affine alignment.

    :ivar affine_alignment: The path to affine_alignment.mat, which is the a transformation matrix generated by ANTsPy for the brain_aligned affine alignment.

    :ivar aparc_aligned: The path to aparc.DKTatlas+aseg.deep_aligned.nii, which is the aparc with the same affine alignment as brain_aligned.

    :ivar brain_aligned_cropped: The path to brain_aligned_cropped.nii, which is the brain_aligned image after cropping. See cropping.py for more information

    :ivar aux_file_list: A set containing all files in the subject directory. This is for convenience and is not used by the class itself.

    :author: Oscar Lloyd-John 
    :contact: sc22olj@leeds.ac.uk
    """

    def __init__(self, path: os.PathLike[str], subject_metadata: pd.DataFrame) -> None:
        """
        Initialises the Subject object
        """

        # Existing before post processing
        self.path = path
        
        self.orig_nu = os.path.join(path, "mri/orig_nu.mgz")
        
        self.mask = os.path.join(path, "mri/mask.mgz")
        
        self.aparc = os.path.join(path, "mri/aparc.DKTatlas+aseg.deep.mgz")
        
        self.subject_metadata = subject_metadata
    
        # Manually assign the column headers as Fastsurfer file is formatted strangely
        header = ['Index', 'SegId', 'NVoxels', 'Volume_mm3', 'StructName', 'normMean', 'normStdDev', 'normMin', 'normMax', 'normRange']
        
        self.aseg_stats = pd.read_csv(os.path.join(path, 'stats/aseg+DKT.stats'), delimiter=r'\s+', comment='#', header=None, names=header)
        
        
        # Existing after post processing
        
        # Affine aligned brain
        brain_aligned = os.path.join(path, "brain_aligned.nii")
        
        self.brain_aligned = brain_aligned if os.path.isfile(brain_aligned) else None
        
        # Affine alignment matrix from ANTsPy
        affine_alignment = os.path.join(path, 'affine_alignment.mat')
        
        self.affine_alignment = affine_alignment if os.path.isfile(affine_alignment) else None
        
        # Aparc file aligned with matrix
        aparc_aligned = os.path.join(path, "aparc.DKTatlas+aseg.deep_aligned.nii")
        
        self.aparc_aligned = aparc_aligned if os.path.isfile(aparc_aligned) else None
        
        # Aligned and cropped brain
        brain_aligned_cropped = os.path.join(path, "brain_aligned_cropped.nii")
        
        self.brain_aligned_cropped = brain_aligned_cropped if os.path.isfile(brain_aligned_cropped) else None
        
        # Set of all files for convenience
        self.aux_file_list = {f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))}
        
def get_cohort_df(data_path: os.PathLike[str]) -> pd.DataFrame:

    """
    Given a dataset directory path, finds all csv files in the directory and parses them into a dataframe. Concatenates all dataframes into one and automatically removes duplicate rows. 
    
    Returns the dataframe unless there are duplicate image IDs. Note that duplicate rows are dropped automatically so duplicate image IDs (having not already been dropped) would suggest the same image with multiple sets of metadata.

    :param data_path: The path to the dataset directory
    :type data_path: os.PathLike[str]
    :returns: A pandas dataframe containing all metadata from the CSVs in the dataset directory. None if duplicate image IDs are found.
    :rtype: pd.DataFrame

    """
    
    csv_list = glob.glob(os.path.join(data_path, "*.csv"))

    # Read all CSVs into a list and concatenate
    cohort_df = pd.concat([pd.read_csv(csv) for csv in csv_list], ignore_index=True)
    
    # Drop duplicate rows
    cohort_df = cohort_df.drop_duplicates(keep='first')
    
    # Find duplicate image IDs
    duplicates = cohort_df[cohort_df.duplicated(subset='Image Data ID', keep=False)]
    
    if not duplicates.empty:
        
        print("Error: duplicate image IDs in CSV")
        
        pprint(duplicates)
        
        return None
    
    return cohort_df

def init_subject(subject_path: os.PathLike[str], cohort_df: pd.DataFrame) -> Subject:

    """
    Given a directory path, checks if it contains the correct structure for a fastsurfer processed file (as processed using module preprocessing_pre_fastsurfer). If it does, creates a Subject object. Otherwise, prints an error message and returns None. Expects a dataframe as input which is used to initialise the Subject object with metadata.

    :param data_path: The path to the dataset directory
    :type data_path: os.PathLike[str]
    :param cohort_df: A dataframe containing metadata for the subjects
    :type cohort_df: pd.DataFrame
    :returns: A subject object, or None if the directory does not contain the correct structure
    :rtype: Subject

    """
    
    def error(item: str):
        
        print(f"Subdirectory {item} does not match the expected format of a fastsurfer processed file. Check that processing was successful\n")
        
        return
        
    # MRI directory of subject path (checking validity)
    mri_path = os.path.join(subject_path, 'mri')
    
    # Check for MRI directory
    if os.path.isdir(mri_path):
        
        orig_file = os.path.join(mri_path, 'orig_nu.mgz')
        
        mask_file = os.path.join(mri_path, 'mask.mgz')

        # If both orig.mgz and mask.mgz exist, create object
        if os.path.isfile(orig_file) and os.path.isfile(mask_file):
            
            # Slice the string after the last underscore to get the image ID
            image_id = subject_path[subject_path.rfind('_') + 1:]
            
            # Get the subject's row using image ID
            subject_metadata = cohort_df.loc[cohort_df['Image Data ID'] == image_id].copy()
            
            if subject_metadata.empty:
                
                print("Error: Image ID not found")
                
                return
            
            return Subject(subject_path, subject_metadata)
        
    error(subject_path)
    
    return None

# Note should probably be refactored to check for format before calling init_subject
def find_subjects_parallel(data_path: os.PathLike[str]) -> list[Subject]:

    """
    Loads the csv file containing data such as image ID, subject ID and disease labels. Note that ADNI gives multiple CSV files with different variable names for some reason! The CSV file that is expected is the one that can be downloaded from the Advanced Image Search results, rather than the csv generated after adding it to a collection. This is because the latter does not contain information such as test scores. Searches the specified directory for subdirectories that could contain subject images. Tries to initialise a Subject object by calling init_subject on each subdirectory. This function is the same as find_subjects except it works in parallel using a process pool executor.

    :param data_path: The path to the dataset directory
    :type data_path: os.PathLike[str]
    :returns: A list of Subject objects
    :rtype: list[Subject]
    """
    
    cohort_df = get_cohort_df(data_path)
    
    subject_list = []
    
    with concurrent.futures.ProcessPoolExecutor() as executor:
        
        futures = []
        
        for item in os.listdir(data_path):
            
            subject_path = os.path.join(data_path, item)
            
            if os.path.isdir(subject_path):
                
                futures.append(executor.submit(init_subject, subject_path, cohort_df))
        
        for future in concurrent.futures.as_completed(futures):
            
            result = future.result()
            
            if result is not None:
                
                subject_list.append(result)
    
    return subject_list
        
        
# Note should probably be refactored to check for format before calling init_subject
def find_subjects(data_path: os.PathLike[str]) -> list[Subject]:

    """
    Loads the csv file containing data such as image ID, subject ID and disease labels. Note that ADNI gives multiple CSV files with different variable names for some reason! The CSV file that is expected is the one that can be downloaded from the Advanced Image Search results, rather than the csv generated after adding it to a collection. This is because the latter does not contain information such as test scores. Searches the specified directory for subdirectories that could contain subject images. Tries to initialise a Subject object by calling init_subject on each subdirectory.

    :param data_path: The path to the dataset directory
    :type data_path: os.PathLike[str]
    :returns: A list of Subject objects
    :rtype: list[Subject]
    """
    
    cohort_df = get_cohort_df(data_path)
    
    subject_list = []
    
    for item in os.listdir(data_path):
        
        subject_path = os.path.join(data_path, item)
        
        if os.path.isdir(subject_path):
                    
            subject_list.append(init_subject(subject_path, cohort_df))

    return subject_list