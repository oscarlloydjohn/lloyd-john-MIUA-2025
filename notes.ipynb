{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "w/c 25/02\n",
    "- Strange issue where first run (from restart) of the model gives convincing results\n",
    "- After this, all epochs (even on restart) predict entirely one class and this class swaps over\n",
    "- Downsampling majority class hasn't fixed this\n",
    "- Could this be to do with argmax. How should I convert outputs into classes\n",
    "- Could it be overfitting? Do i need more data\n",
    "- After 7 epochs, got 65% accuracy with non downsampled majority, learning rate of 0.0001\n",
    "\n",
    "w/c 3/03\n",
    "- Got more data\n",
    "- Adjusted sampling of both datasets to use uniform sampling at 2048 samples\n",
    "- Initial dataset with new sampling results looked similar (first few epochs)\n",
    "- Large dataset with new sampling results looked similar (first few epochs)\n",
    "- Validation loss is much larger than training loss, could mean overfitting\n",
    "- Could overfitting be to do with lack of smoothing after walking cubes?\n",
    "- Training with only one image per subject gives approx 200 subjects, seems to overfit and train poorly\n",
    "- Would similar images of the same subject cause overfitting or could it be considered data augmentation?\n",
    "\n",
    "6/05\n",
    "- Trained multiple models overnight, when preventing data leakage accuracy is poor and overfitting is happening\n",
    "- Learning rate doesn't have much effect as all are overfitted\n",
    "- Single image per subject is also overfitted \n",
    "- Going to try with ssg rather than msg\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
