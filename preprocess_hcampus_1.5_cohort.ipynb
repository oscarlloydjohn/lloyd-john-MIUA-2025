{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sample\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Custom modules\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing_post_fastsurfer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malignment\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing_post_fastsurfer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcropping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing_post_fastsurfer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextraction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[31mImportError\u001b[39m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import sample\n",
    "\n",
    "# Custom modules\n",
    "from preprocessing_post_fastsurfer.alignment import *\n",
    "from preprocessing_post_fastsurfer.cropping import *\n",
    "from preprocessing_post_fastsurfer.extraction import *\n",
    "from preprocessing_post_fastsurfer.file_handling import *\n",
    "from preprocessing_post_fastsurfer.mesh_creation import *\n",
    "from preprocessing_post_fastsurfer.subject import *\n",
    "from preprocessing_post_fastsurfer.vis import *\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference brain\n",
    "Extract the brain from the MRI reference MRI for use in affine alginment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB seems that fastsrufer brain is better\n",
    "reference_brain_array_mni = extract_brain(\"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/mni_icbm152_lin_nifti/icbm_avg_152_t1_tal_lin.nii\", \"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/mni_icbm152_lin_nifti/icbm_avg_152_t1_tal_lin_mask.nii\")\n",
    "\n",
    "display_array(reference_brain_array_mni)\n",
    "\n",
    "reference_brain_array_fastsurfer = extract_brain(\"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/mni_icbm152_lin_nifti/fastsurfer-processed/mri/orig_nu.mgz\", \"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/mni_icbm152_lin_nifti/fastsurfer-processed/mri/mask.mgz\")\n",
    "\n",
    "display_array(reference_brain_array_fastsurfer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a list of subject objects from the given directory\n",
    "data_path = \"/uolstore/home/users/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/scratch-disk/full-datasets/hcampus-1.5T-cohort\"\n",
    "\n",
    "subject_list = find_subjects_parallel(data_path)\n",
    "\n",
    "print(len(subject_list))\n",
    "\n",
    "# Chunk the subject list\n",
    "def chunk_list(list, chunk_size):\n",
    "    \n",
    "    return [list[i:i + chunk_size] for i in range(0, len(list), chunk_size)]\n",
    "\n",
    "chunks = chunk_list(subject_list, len(subject_list) // 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform affine alignment on all subjects in the list, using the reference brain\n",
    "alignment_parallel(subject_list, reference_brain_array_fastsurfer, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop all aligned brains to remove empty space\n",
    "max_bbox = get_max_bbox(subject_list, 'brain_aligned.nii')\n",
    "\n",
    "crop_subjects_parallel(subject_list, 'brain_aligned.nii', max_bbox, is_full_brain=True, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align the parcellation file using the same affine transformation used on the brain\n",
    "# NB affine alinged aparcs may be inaccurate\n",
    "for chunk in chunks:\n",
    "    \n",
    "    aux_alignment_parallel(chunk, 'aparc', is_aparc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract left and right hippocampus from non-aligned brains (in the same file)\n",
    "for chunk in chunks:\n",
    "    \n",
    "    extract_region_parallel(chunk, [17, 53], 'orig_nu', 'aparc', is_aligned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop hippocampi\n",
    "max_bbox = get_max_bbox(subject_list, 'Left-Hippocampus_Right-Hippocampus.nii')\n",
    "\n",
    "for chunk in chunks:\n",
    "    \n",
    "    crop_subjects_parallel(chunk, 'Left-Hippocampus_Right-Hippocampus.nii', max_bbox, is_full_brain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract left and right hippocampus from aligned brains (in the same file)\n",
    "for chunk in chunks:\n",
    "    \n",
    "    extract_region_parallel(chunk, [17, 53], 'brain_aligned', 'aparc_aligned', is_aligned=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop aligned hippocampi\n",
    "max_bbox = get_max_bbox(subject_list, 'Left-Hippocampus_Right-Hippocampus_aligned.nii')\n",
    "\n",
    "for chunk in chunks:\n",
    "    \n",
    "    crop_subjects_parallel(chunk, 'Left-Hippocampus_Right-Hippocampus_aligned.nii', max_bbox, is_full_brain=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract left hippocampus alone from non-aligned brains\n",
    "for chunk in chunks:\n",
    "    \n",
    "    extract_region_parallel(chunk, [17], 'orig_nu', 'aparc', is_aligned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop non-aligned left hippocampi\n",
    "max_bbox = get_max_bbox(subject_list, 'Left-Hippocampus.nii')\n",
    "\n",
    "for chunk in chunks:\n",
    "    \n",
    "    crop_subjects_parallel(chunk, 'Left-Hippocampus.nii', max_bbox, is_full_brain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract left hippocampus alone from aligned brains\n",
    "for chunk in chunks:\n",
    "    \n",
    "    extract_region_parallel(chunk, [17], 'brain_aligned', 'aparc_aligned', is_aligned=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop non-aligned left hippocampi\n",
    "max_bbox = get_max_bbox(subject_list, 'Left-Hippocampus_aligned.nii')\n",
    "\n",
    "for chunk in chunks:\n",
    "    \n",
    "    crop_subjects_parallel(chunk, 'Left-Hippocampus_aligned.nii', max_bbox, is_full_brain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify smoothing parameters\n",
    "for subject in subject_list:\n",
    "    display_mesh(volume_to_mesh(subject, 'Left-Hippocampus_Right-Hippocampus_aligned_cropped.nii', smooth=False))\n",
    "    \n",
    "    display_mesh(volume_to_mesh(subject, 'Left-Hippocampus_Right-Hippocampus_aligned_cropped.nii', smooth=True, number_of_iterations=5, lambda_filter=1.2))\n",
    "    \n",
    "    #display_mesh(volume_to_mesh(subject, 'Left-Hippocampus_Right-Hippocampus_cropped.nii', smooth=False))\n",
    "    \n",
    "    #display_mesh(volume_to_mesh(subject, 'Left-Hippocampus_Right-Hippocampus_cropped.nii', smooth=True, number_of_iterations=4, lambda_filter=0.9))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert cropped hippocampi point clouds using walking cubes method\n",
    "volume_to_mesh_parallel(subject_list, 'Left-Hippocampus_Right-Hippocampus_cropped.nii', display=False, smooth=True, number_of_iterations=5, lambda_filter=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert aligned cropped hippocampi point clouds using walking cubes method\n",
    "volume_to_mesh_parallel(subject_list, 'Left-Hippocampus_Right-Hippocampus_aligned_cropped.nii', display=False, smooth=True, number_of_iterations=5, lambda_filter=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert cropped hippocampi point clouds using walking cubes method\n",
    "volume_to_mesh_parallel(subject_list, 'Left-Hippocampus_cropped.nii', display=False, smooth=True, number_of_iterations=5, lambda_filter=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert aligned cropped hippocampi point clouds using walking cubes method\n",
    "volume_to_mesh_parallel(subject_list, 'Left-Hippocampus_aligned_cropped.nii', display=False, smooth=True, number_of_iterations=5, lambda_filter=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all non-cropped hippocampi\n",
    "for subject in subject_list:\n",
    "    \n",
    "    delete_file_matching(subject.path, 'Left-Hippocampus_Right-Hippocampus.nii')\n",
    "    \n",
    "    delete_file_matching(subject.path, 'Left-Hippocampus_Right-Hippocampus_aligned.nii')\n",
    "    \n",
    "    delete_file_matching(subject.path, 'Left-Hippocampus.nii')\n",
    "    \n",
    "    delete_file_matching(subject.path, 'Left-Hippocampus_aligned.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check minimum number of points in dataset such that we don't sample below\n",
    "get_min_cloud_points(subject_list, 'Left-Hippocampus_Right-Hippocampus_cropped_mesh.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample all hippocampi clouds to have the same vector size for use in pytorch\n",
    "downsample_cloud_parallel(subject_list, 'Left-Hippocampus_Right-Hippocampus_cropped_mesh.npz', 2048, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check minimum number of points in dataset such that we don't sample below\n",
    "get_min_cloud_points(subject_list, 'Left-Hippocampus_Right-Hippocampus_aligned_cropped_mesh.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample all aligned hippocampi clouds to have the same vector size for use in pytorch\n",
    "downsample_cloud_parallel(subject_list, 'Left-Hippocampus_Right-Hippocampus_aligned_cropped_mesh.npz', 2048, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check minimum number of points in dataset such that we don't sample below\n",
    "get_min_cloud_points(subject_list, 'Left-Hippocampus_cropped_mesh.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample all hippocampi clouds to have the same vector size for use in pytorch\n",
    "downsample_cloud_parallel(subject_list, 'Left-Hippocampus_cropped_mesh.npz', 1024, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check minimum number of points in dataset such that we don't sample below\n",
    "get_min_cloud_points(subject_list, 'Left-Hippocampus_aligned_cropped_mesh.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample all aligned hippocampi clouds to have the same vector size for use in pytorch\n",
    "downsample_cloud_parallel(subject_list, 'Left-Hippocampus_aligned_cropped_mesh.npz', 1024, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise a subject\n",
    "subject = sample(subject_list, 1)[0]\n",
    "    \n",
    "research_group = subject.subject_metadata['Group'].iloc[0]\n",
    "\n",
    "print(research_group)\n",
    "\n",
    "display_image(nibabel.load(subject.orig_nu))\n",
    "\n",
    "display_image(nibabel.load(subject.brain_aligned_cropped))\n",
    "\n",
    "display_image_3d(nibabel.load(subject.brain_aligned_cropped), 1)\n",
    "\n",
    "display_mesh(np.load(os.path.join(subject.path, 'Left-Hippocampus_Right-Hippocampus_cropped_mesh.npz')))\n",
    "\n",
    "display_cloud(np.load(os.path.join(subject.path, 'Left-Hippocampus_Right-Hippocampus_cropped_mesh_downsampledcloud.npy')))\n",
    "\n",
    "display_mesh(np.load(os.path.join(subject.path, 'Left-Hippocampus_Right-Hippocampus_aligned_cropped_mesh.npz')))\n",
    "\n",
    "display_cloud(np.load(os.path.join(subject.path, 'Left-Hippocampus_Right-Hippocampus_aligned_cropped_mesh_downsampledcloud.npy')))\n",
    "\n",
    "display_mesh(np.load(os.path.join(subject.path, 'Left-Hippocampus_cropped_mesh.npz')))\n",
    "\n",
    "display_cloud(np.load(os.path.join(subject.path, 'Left-Hippocampus_cropped_mesh_downsampledcloud.npy')))\n",
    "\n",
    "display_mesh(np.load(os.path.join(subject.path, 'Left-Hippocampus_aligned_cropped_mesh.npz')))\n",
    "\n",
    "display_cloud(np.load(os.path.join(subject.path, 'Left-Hippocampus_aligned_cropped_mesh_downsampledcloud.npy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
