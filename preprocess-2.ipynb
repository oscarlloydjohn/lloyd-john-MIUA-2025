{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules for debugging\n",
    "'''\n",
    "import nibabel\n",
    "from PIL import Image\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import ants\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import xmltodict\n",
    "import shutil\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Custom modules\n",
    "from preprocessing_post_fastsurfer.alignment import *\n",
    "from preprocessing_post_fastsurfer.cropping import *\n",
    "from preprocessing_post_fastsurfer.extraction import *\n",
    "from preprocessing_post_fastsurfer.file_handling import *\n",
    "from preprocessing_post_fastsurfer.mesh_creation import *\n",
    "from preprocessing_post_fastsurfer.subject import *\n",
    "from preprocessing_post_fastsurfer.vis import *\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference brain\n",
    "Extract the brain from the MRI reference MRI for use in affine alginment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB seems that fastsrufer brain is better\n",
    "reference_brain_array_mni = extract_brain(\"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/mni_icbm152_lin_nifti/icbm_avg_152_t1_tal_lin.nii\", \"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/mni_icbm152_lin_nifti/icbm_avg_152_t1_tal_lin_mask.nii\")\n",
    "\n",
    "display_array(reference_brain_array_mni)\n",
    "\n",
    "reference_brain_array_fastsurfer = extract_brain(\"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/mni_icbm152_lin_nifti/fastsurfer-processed/mri/orig_nu.mgz\", \"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/mni_icbm152_lin_nifti/fastsurfer-processed/mri/mask.mgz\")\n",
    "\n",
    "display_array(reference_brain_array_fastsurfer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a list of subject objects from the given directory\n",
    "data_path = \"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/scratch disk/full-datasets/adni1-complete-3T-processed\"\n",
    "\n",
    "subject_list = find_subjects(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform affine alignment on all subjects in the list, using the reference brain\n",
    "alignment_parallel(subject_list, reference_brain_array_fastsurfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop all aligned brains to remove empty space\n",
    "crop_subjects_parallel(subject_list, 'brain_aligned.nii', is_full_brain=True, display_3d=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align the parcellation file using the same affine transformation used on the brain\n",
    "# NB affine alinged aparcs may be inaccurate\n",
    "aux_alignment_parallel(subject_list, 'aparc', is_aparc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract left and right hippocampus from non-aligned brains (in the same file)\n",
    "extract_region_parallel(subject_list, [17, 53], 'orig_nu', 'aparc', is_aligned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop hippocampi\n",
    "crop_subjects_parallel(subject_list, 'Left-Hippocampus_Right-Hippocampus.nii', is_full_brain=False, display_3d=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract left and right hippocampus from aligned brains (in the same file)\n",
    "extract_region_parallel(subject_list, [17, 53], 'brain_aligned', 'aparc_aligned', is_aligned=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop hippocampi\n",
    "crop_subjects_parallel(subject_list, 'Left-Hippocampus_Right-Hippocampus_aligned.nii', is_full_brain=False, display_3d=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert cropped hippocampi point clouds using walking cubes method\n",
    "volume_to_mesh_parallel(subject_list, 'Left-Hippocampus_Right-Hippocampus_cropped.nii', downsample_factor=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert aligned cropped hippocampi point clouds using walking cubes method\n",
    "volume_to_mesh_parallel(subject_list, 'Left-Hippocampus_Right-Hippocampus_aligned_cropped.nii', downsample_factor=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all non-cropped hippocampi\n",
    "for subject in subject_list:\n",
    "    \n",
    "    delete_file_matching(subject.path, 'Left-Hippocampus_Right-Hippocampus.nii')\n",
    "    \n",
    "    delete_file_matching(subject.path, 'Left-Hippocampus_Right-Hippocampus_aligned.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample all hippocampi meshes to have the same vector size for use in pytorch\n",
    "random_sample_mesh_parallel(subject_list, 'Left-Hippocampus_Right-Hippocampus_cropped_mesh.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample_mesh_parallel(subject_list, 'Left-Hippocampus_Right-Hippocampus_aligned_cropped_mesh.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1yr 3t size before 135gb\n",
    "# 1yr 3t size after  55gb\n",
    "\n",
    "# Note write about storage size in report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Data type testing\n",
    "for subject in subject_list:\n",
    "    \n",
    "    image = nibabel.load(os.path.join(subject.path, subject.mask))\n",
    "    \n",
    "    print(image.header)\n",
    "    \n",
    "    print(image.dataobj.dtype)\n",
    "    \n",
    "    print(np.max(image.dataobj))\n",
    "    \n",
    "    print(image.get_fdata().dtype)\n",
    "    \n",
    "    print(np.max(image.get_fdata()))\n",
    "    \n",
    "    new_image = nibabel.Nifti1Image(np.asarray(image.dataobj).astype('uint32'), np.eye(4))\n",
    "    \n",
    "    print(new_image.dataobj.dtype)\n",
    "    \n",
    "    print(np.max(new_image.dataobj))\n",
    "    \n",
    "    break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subject_list:\n",
    "    \n",
    "    subject_dict = subject.xml_df\n",
    "    \n",
    "    research_group = subject_dict['idaxs']['project']['subject']['researchGroup']\n",
    "    \n",
    "    visit_identifier = subject_dict['idaxs']['project']['subject']['visit']['visitIdentifier']\n",
    "    \n",
    "    sex = subject_dict['idaxs']['project']['subject']['subjectSex']\n",
    "    \n",
    "    age = subject_dict['idaxs']['project']['subject']['study']['subjectAge']\n",
    "    \n",
    "    weight = subject_dict['idaxs']['project']['subject']['study']['weightKg']\n",
    "    \n",
    "    apoe_a1 = subject_dict['idaxs']['project']['subject']['subjectInfo'][0]['#text']\n",
    "    \n",
    "    apoe_a2 = subject_dict['idaxs']['project']['subject']['subjectInfo'][1]['#text']\n",
    "    \n",
    "    print(research_group)\n",
    "    \n",
    "    print(visit_identifier)\n",
    "    \n",
    "    print(sex)\n",
    "    \n",
    "    print(age)\n",
    "    \n",
    "    print(weight)\n",
    "    \n",
    "    print(apoe_a1)\n",
    "    \n",
    "    print(apoe_a2)\n",
    "\n",
    "    # Assessment scores, not all are present for a given subject\n",
    "    mmscore = None\n",
    "    gdtotal = None\n",
    "    cdglobal = None\n",
    "    faqtotalscore = None\n",
    "    npiscore = None\n",
    "    \n",
    "    assessments = subject_dict['idaxs']['project']['subject']['visit']['assessment']\n",
    "    \n",
    "    print(assessments)\n",
    "    \n",
    "    for assessment in assessments:\n",
    "        # Loop through each component in the assessment\n",
    "        for component in assessment['component']:\n",
    "            # Extract the assessmentScore element and its attribute\n",
    "            \n",
    "            print(component[0]['#text'])\n",
    "            \n",
    "            #assessment_score = component['assessmentScore']\n",
    "            \n",
    "            \n",
    "            '''attribute = assessment_score.get('@attribute')  # Get the attribute name\n",
    "            score = assessment_score.text.strip() if assessment_score.text else None\n",
    "\n",
    "            # Check for the corresponding score based on the attribute\n",
    "            if attribute == \"MMSCORE\":\n",
    "                mmscore = score\n",
    "            elif attribute == \"GDTOTAL\":\n",
    "                gdtotal = score\n",
    "            elif attribute == \"CDGLOBAL\":\n",
    "                cdglobal = score\n",
    "            elif attribute == \"FAQTOTAL\":\n",
    "                faqtotalscore = score\n",
    "            elif attribute == \"NPISCORE\":\n",
    "                npiscore = score'''\n",
    "\n",
    "    # Print the extracted scores\n",
    "    print(f\"MMSCORE: {mmscore}\")\n",
    "    print(f\"GDTOTAL: {gdtotal}\")\n",
    "    print(f\"CDGLOBAL: {cdglobal}\")\n",
    "    print(f\"FAQTOTAL: {faqtotalscore}\")\n",
    "    print(f\"NPISCORE: {npiscore}\")\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
