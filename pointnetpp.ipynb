{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torcheval.metrics import *\n",
    "\n",
    "# Benny pointnet\n",
    "from pointnet2_benny import pointnet2_cls_msg\n",
    "from pointnet2_benny import provider\n",
    "\n",
    "# Other\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "# Custom modules\n",
    "from preprocessing_post_fastsurfer.subject import *\n",
    "from preprocessing_post_fastsurfer.vis import *\n",
    "from ozzy_torch_utils.split_dataset import *\n",
    "from ozzy_torch_utils.SubjectDataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/scratch-disk/full-datasets/hcampus-large-cohort\"\n",
    "\n",
    "selected_labels = ['CN', 'MCI']\n",
    "\n",
    "# Dictionary key representing the data of interest\n",
    "data_string = 'hcampus_pointcloud'\n",
    "\n",
    "# Dictionary key representing the disease labels\n",
    "labels_string = 'research_group'\n",
    "\n",
    "downsample_majority=True\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SubjectDataset(data_path, selected_labels, downsample_majority=downsample_majority)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset size: {len(dataset)}\\n\")\n",
    "\n",
    "'''labels = []\n",
    "\n",
    "for subject in range(len(dataset.subject_list)):\n",
    "    \n",
    "    group = dataset.__getitem__(subject)['research_group']\n",
    "    \n",
    "    labels.append(group)\n",
    "    \n",
    "print(f\"Unique labels: {np.unique(labels)}\\n\")\n",
    "\n",
    "print(\"Labels count: \")\n",
    "print(Counter(labels))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loader config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data, test_data = split_dataset(dataset, test_size=test_size)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn([data_string, labels_string]))\n",
    "\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn([data_string, labels_string]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "w/c 25/02\n",
    "- Strange issue where first run (from restart) of the model gives convincing results\n",
    "- After this, all epochs (even on restart) predict entirely one class and this class swaps over\n",
    "- Downsampling majority class hasn't fixed this\n",
    "- Could this be to do with argmax. How should I convert outputs into classes\n",
    "- Could it be overfitting? Do i need more data\n",
    "- After 7 epochs, got 65% accuracy with non downsampled majority, learning rate of 0.0001\n",
    "\n",
    "w/c 3/03\n",
    "- Got more data\n",
    "- Adjusted sampling of both datasets to use uniform sampling at 2048 samples\n",
    "- Initial dataset with new sampling results looked similar (first few epochs)\n",
    "- Large dataset with new sampling results looked similar (first few epochs)\n",
    "- Validation loss is much larger than training loss, could mean overfitting\n",
    "- Could overfitting be to do with lack of smoothing after walking cubes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inplace relu from benny pointnet\n",
    "def inplace_relu(m):\n",
    "    \n",
    "    classname = m.__class__.__name__\n",
    "    \n",
    "    if classname.find('ReLU') != -1:\n",
    "        \n",
    "        m.inplace=True\n",
    "\n",
    "num_classes = dataset.num_classes\n",
    "\n",
    "training_losses, validation_losses, conf_matrices, accuracies, f1s, precisions, recalls = [], [], [], [], [], [], []\n",
    "\n",
    "model = pointnet2_cls_msg.get_model(num_classes, normal_channel=False)\n",
    "\n",
    "criterion = pointnet2_cls_msg.get_loss()\n",
    "\n",
    "# Benny inplace relu\n",
    "model.apply(inplace_relu)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4, amsgrad=True)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=0.001,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-08,\n",
    "            weight_decay=1e-4,\n",
    "            amsgrad=True\n",
    "        )\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    print(f\"Starting epoch {epoch + 1}\\n\")\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, dict in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "        \n",
    "        # Access dict returned by dataset __getitem__\n",
    "        points = dict[data_string]\n",
    "        labels = dict[labels_string]\n",
    "        \n",
    "        # Transpose as in benny script (NB why does it need a transpose)\n",
    "        points = points.transpose(2, 1)\n",
    "        \n",
    "        points, labels = points.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output, _ = model(points)\n",
    "\n",
    "        # Calculate loss, trans_feat argument as None as not used in this function\n",
    "        loss = criterion(output, labels, None)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Multiply loss by batch size to account for differences in batch size (e.g last batch)\n",
    "        running_loss += loss.item() * points.size(0)\n",
    "        \n",
    "    training_losses.append(running_loss/len(train_dataloader))\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "        \n",
    "    conf_matrix = BinaryConfusionMatrix()\n",
    "    \n",
    "    accuracy = BinaryAccuracy()\n",
    "    \n",
    "    f1 = BinaryF1Score()\n",
    "\n",
    "    precision = BinaryPrecision()\n",
    "    \n",
    "    recall = BinaryRecall()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch_idx, dict in enumerate(test_dataloader):\n",
    "            \n",
    "            points = dict[data_string]\n",
    "            labels = dict[labels_string]\n",
    "            \n",
    "            points = points.transpose(2, 1)\n",
    "            \n",
    "            points, labels = points.to(device), labels.to(device)\n",
    "            \n",
    "            output, _ = model(points)\n",
    "            \n",
    "            running_loss += criterion(output, labels, None).item() * points.size(0)\n",
    "            \n",
    "            # Apply exponent as the output of the model is log softmax\n",
    "            pred_probability = torch.exp(output)\n",
    "            \n",
    "            # Threshold is variable to give preference to FN or FP\n",
    "            pred_labels = (pred_probability[:, 1] >= threshold).int()\n",
    "            \n",
    "            # Old label conversion\n",
    "            # pred_labels = torch.argmax(pred_probability, dim=-1)\n",
    "\n",
    "            # Update metrics\n",
    "            [metric.update(pred_labels, labels) for metric in [conf_matrix, accuracy, f1, precision, recall]]\n",
    "\n",
    "    end_time = datetime.now()\n",
    "            \n",
    "    # Append metric lists\n",
    "    [metric_list.append(metric.compute()) for metric_list, metric in [(conf_matrices, conf_matrix), (accuracies, accuracy), (f1s, f1), (precisions, precision), (recalls, recall)]]\n",
    "            \n",
    "    validation_losses.append(running_loss/len(test_dataloader))\n",
    "                    \n",
    "    #ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=selected_labels).plot()\n",
    "    \n",
    "    print(conf_matrix.compute())\n",
    "    \n",
    "    print(f\"\\n Epoch {epoch + 1} complete\\n\")\n",
    "    print(f\"Training loss: {training_losses[-1]}\\n\")\n",
    "    print(f\"Validation loss: {validation_losses[-1]}\\n\")\n",
    "    print(f\"Accuracy: {accuracies[-1]}\\n\")\n",
    "    print(f\"F1: {f1s[-1]}\\n\")\n",
    "    print(f\"Precision: {precisions[-1]}\\n\")\n",
    "    print(f\"Recall: {recalls[-1]}\\n\")\n",
    "    print(\"------------------------\\n\\n\\n\")\n",
    "    \n",
    "    # Break before nightly restart\n",
    "    current_time = datetime.now()\n",
    "    \n",
    "    if current_time.hour == 23 and current_time.minute >= 30:\n",
    "        print(\"Break before nightly restart\")\n",
    "        break\n",
    "\n",
    "torch.save(model.state_dict(), 'trained_model.pth')\n",
    "print(\"Training complete and model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute best epoch and the stats of this epoch\n",
    "best_epoch = validation_losses.index(min(validation_losses))\n",
    "\n",
    "train_time = end_time - start_time\n",
    "\n",
    "minutes = train_time.seconds // 60\n",
    "\n",
    "seconds = train_time.seconds % 60\n",
    "\n",
    "train_time_str = f\"Training time: {minutes:02d}m {seconds:02d}s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss, validation loss, and accuracy on separate subplots, along with displaying hyperparameters\n",
    "def plot(training_losses, \n",
    "         validation_losses, \n",
    "         train_time_str, \n",
    "         accuracies, \n",
    "         f1s, \n",
    "         precisions, \n",
    "         recalls, \n",
    "         param_list,\n",
    "         name=None):\n",
    "    \n",
    "    best_epoch = accuracies.index(max(accuracies))\n",
    "    best_accuracy = accuracies[best_epoch]\n",
    "    best_f1 = f1s[best_epoch]\n",
    "    best_precision = precisions[best_epoch]\n",
    "    best_recall = recalls[best_epoch]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10), sharex=True)\n",
    "    \n",
    "    ax1.plot(training_losses, label='Training Loss', color='blue', marker='x')\n",
    "    ax1.plot(validation_losses, label='Validation Loss', color='red', marker='x')\n",
    "    ax1.set_title('Training and Validation Loss over Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    ax2.plot(accuracies, label='Accuracy', color='green', marker='o')\n",
    "    ax2.set_title('Accuracy over Epochs')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    ax2.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    info = []\n",
    "    info.append(train_time_str)\n",
    "    info.append(f\"Best epoch Accuracy: {best_accuracy:.2f}\")\n",
    "    info.append(f\"Best epoch F1 Score: {best_f1:.2f}\")\n",
    "    info.append(f\"Best epoch Precision: {best_precision:.2f}\")\n",
    "    info.append(f\"Best epoch Recall: {best_recall:.2f}\")\n",
    "    info.append(\"\\n\\n\")\n",
    "\n",
    "    for param in param_list:\n",
    "        for name, value in globals().items():\n",
    "            if value is param:\n",
    "                info.append(f\"{name}: {value}\")\n",
    "    \n",
    "    info_text = \"\\n\".join(info)\n",
    "    \n",
    "    fig.text(0.5, 0.02, info_text, ha='center', va='top', wrap=True, fontsize=10)\n",
    "\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") \n",
    "    name = f\"plot_{current_time}\"\n",
    "    plt.savefig(f'/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/figs/{name}.png', bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot(training_losses, \n",
    "     validation_losses, \n",
    "     train_time_str, \n",
    "     accuracies, \n",
    "     f1s, \n",
    "     precisions, \n",
    "     recalls, \n",
    "     [selected_labels, data_string, labels_string, downsample_majority, batch_size, test_size, learning_rate, num_epochs, threshold],\n",
    "     name=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
