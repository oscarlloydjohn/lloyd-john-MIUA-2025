{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torcheval.metrics import *\n",
    "\n",
    "# 3d cnn\n",
    "import cnn3d_xmuyzz\n",
    "\n",
    "# Other\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import pickle\n",
    "# Custom modules\n",
    "from preprocessing_post_fastsurfer.subject import *\n",
    "from preprocessing_post_fastsurfer.vis import *\n",
    "from ozzy_torch_utils.split_dataset import *\n",
    "from ozzy_torch_utils.SubjectDataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/scratch-disk/full-datasets/hcampus-large-cohort\"\n",
    "\n",
    "selected_labels = ['CN', 'MCI']\n",
    "\n",
    "# Dictionary key representing the data of interest\n",
    "data_string = 'hcampus_vox_aligned'\n",
    "\n",
    "# Dictionary key representing the disease labels\n",
    "labels_string = 'research_group'\n",
    "\n",
    "# Prevent class imbalance\n",
    "downsample_majority = True\n",
    "\n",
    "# NB this argument makes prevent_id_leakage redundant\n",
    "single_img_per_subject = False\n",
    "\n",
    "# Prevent the same subject id from occuring in train and test, in case of more than one image per id\n",
    "prevent_id_leakage = True\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SubjectDataset(data_path, selected_labels, downsample_majority=downsample_majority, single_img_per_subject=single_img_per_subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data checks\n",
    "\n",
    "Check the size of the dataset and the number of unique labels and IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 3926\n",
      "\n",
      "Unique labels: (array([0, 1]), array([1963, 1963]))\n",
      "\n",
      "Unique ids: (array(['003_S_0908', '003_S_1074', '003_S_4081', '003_S_4119',\n",
      "       '003_S_4288', '003_S_4350', '003_S_4441', '003_S_4555',\n",
      "       '003_S_4644', '003_S_4872', '003_S_4900', '003_S_5154',\n",
      "       '005_S_0324', '005_S_0448', '005_S_0553', '005_S_0572',\n",
      "       '005_S_0602', '005_S_4168', '007_S_1206', '007_S_1222',\n",
      "       '007_S_2394', '007_S_4272', '007_S_4387', '007_S_4488',\n",
      "       '007_S_4516', '007_S_4620', '007_S_4637', '007_S_5265',\n",
      "       '009_S_0751', '009_S_0842', '009_S_1030', '009_S_4337',\n",
      "       '009_S_4388', '009_S_4612', '011_S_0021', '011_S_0023',\n",
      "       '011_S_1080', '011_S_1282', '011_S_4075', '011_S_4105',\n",
      "       '011_S_4120', '011_S_4222', '011_S_4278', '013_S_1035',\n",
      "       '013_S_1186', '013_S_1276', '013_S_4579', '013_S_4580',\n",
      "       '013_S_4616', '014_S_4080', '014_S_4093', '014_S_4401',\n",
      "       '014_S_4576', '014_S_4577', '016_S_0769', '016_S_1117',\n",
      "       '016_S_1121', '016_S_1138', '016_S_1149', '016_S_1326',\n",
      "       '016_S_4097', '016_S_4121', '016_S_4638', '016_S_4688',\n",
      "       '016_S_4951', '016_S_4952', '020_S_1288', '021_S_4254',\n",
      "       '021_S_4276', '021_S_4335', '021_S_4421', '021_S_4558',\n",
      "       '022_S_4173', '022_S_4196', '022_S_4266', '022_S_4291',\n",
      "       '022_S_4320', '023_S_0030', '023_S_0031', '023_S_0058',\n",
      "       '023_S_0061', '023_S_0078', '023_S_0331', '023_S_0376',\n",
      "       '023_S_0388', '023_S_0604', '023_S_0613', '023_S_0625',\n",
      "       '023_S_0855', '023_S_0926', '023_S_0963', '023_S_1046',\n",
      "       '023_S_1104', '023_S_1126', '023_S_1190', '023_S_1247',\n",
      "       '023_S_4020', '023_S_4115', '023_S_4164', '023_S_4448',\n",
      "       '024_S_4084', '024_S_4158', '027_S_0307', '027_S_0403',\n",
      "       '027_S_0835', '027_S_1277', '027_S_1387', '027_S_2245',\n",
      "       '027_S_4919', '029_S_0824', '029_S_0914', '029_S_4279',\n",
      "       '029_S_4290', '029_S_4384', '029_S_4385', '029_S_4585',\n",
      "       '029_S_4652', '029_S_5219', '031_S_0568', '031_S_0830',\n",
      "       '031_S_1066', '032_S_0187', '032_S_0479', '032_S_0677',\n",
      "       '032_S_1169', '032_S_4277', '032_S_4348', '032_S_4386',\n",
      "       '032_S_4429', '032_S_4921', '033_S_0514', '033_S_0725',\n",
      "       '033_S_0920', '033_S_0922', '033_S_1016', '033_S_1086',\n",
      "       '033_S_1098', '033_S_1116', '033_S_1279', '033_S_1309',\n",
      "       '033_S_4176', '033_S_4177', '033_S_4179', '033_S_4505',\n",
      "       '033_S_4508', '033_S_5198', '035_S_0555', '035_S_4082',\n",
      "       '035_S_4464', '035_S_4785', '036_S_4389', '036_S_4491',\n",
      "       '036_S_4878', '037_S_0150', '037_S_0303', '037_S_0377',\n",
      "       '037_S_0454', '037_S_0467', '037_S_0501', '037_S_0566',\n",
      "       '037_S_0588', '037_S_1078', '037_S_1225', '037_S_4028',\n",
      "       '037_S_4071', '037_S_4214', '037_S_4308', '037_S_4410',\n",
      "       '037_S_5126', '041_S_1418', '041_S_4014', '041_S_4037',\n",
      "       '041_S_4041', '041_S_4051', '041_S_4060', '041_S_4200',\n",
      "       '041_S_4427', '041_S_4874', '041_S_5100', '041_S_5253',\n",
      "       '051_S_1072', '051_S_1123', '051_S_1131', '051_S_1331',\n",
      "       '051_S_1338', '052_S_1250', '052_S_1251', '052_S_4944',\n",
      "       '067_S_0056', '067_S_0059', '067_S_0257', '067_S_0290',\n",
      "       '067_S_0607', '068_S_0210', '068_S_0473', '068_S_0802',\n",
      "       '068_S_4174', '068_S_4340', '068_S_4424', '070_S_4856',\n",
      "       '070_S_5040', '072_S_4103', '072_S_4391', '073_S_0089',\n",
      "       '073_S_0311', '073_S_0746', '073_S_4155', '073_S_4382',\n",
      "       '073_S_4393', '073_S_4552', '073_S_4559', '073_S_4739',\n",
      "       '073_S_4762', '073_S_4795', '073_S_5023', '073_S_5167',\n",
      "       '082_S_0304', '082_S_0928', '082_S_1256', '082_S_2121',\n",
      "       '082_S_4090', '082_S_4208', '082_S_4224', '082_S_4339',\n",
      "       '082_S_4428', '094_S_1241', '094_S_1267', '094_S_1293',\n",
      "       '094_S_4234', '094_S_4503', '094_S_4560', '094_S_4649',\n",
      "       '098_S_4003', '098_S_4018', '098_S_4050', '098_S_4275',\n",
      "       '098_S_4506', '099_S_4076', '099_S_4086', '099_S_4104',\n",
      "       '109_S_4499', '114_S_0173', '114_S_0416', '114_S_2392',\n",
      "       '116_S_0382', '116_S_0649', '116_S_0752', '116_S_1232',\n",
      "       '116_S_1249', '116_S_4010', '116_S_4043', '116_S_4092',\n",
      "       '116_S_4453', '116_S_4483', '116_S_4855', '123_S_4127',\n",
      "       '126_S_0405', '126_S_0605', '126_S_1340', '126_S_4514',\n",
      "       '127_S_0260', '127_S_0393', '127_S_0397', '127_S_0622',\n",
      "       '127_S_4148', '127_S_4198', '127_S_4604', '127_S_4645',\n",
      "       '127_S_4843', '128_S_1088', '128_S_1148', '128_S_1242',\n",
      "       '128_S_2123', '128_S_4586', '128_S_4599', '128_S_4607',\n",
      "       '128_S_4609', '128_S_4742', '128_S_4832', '129_S_0778',\n",
      "       '129_S_4369', '129_S_4371', '129_S_4396', '129_S_4422',\n",
      "       '131_S_0123', '131_S_0384', '131_S_0441', '131_S_1301',\n",
      "       '131_S_1389', '133_S_0433', '133_S_0488', '133_S_0493',\n",
      "       '133_S_0525', '133_S_0629', '133_S_0638', '133_S_0727',\n",
      "       '133_S_0771', '133_S_0792', '133_S_0912', '133_S_0913',\n",
      "       '133_S_1031', '135_S_4356', '135_S_4446', '135_S_4489',\n",
      "       '135_S_4566', '135_S_4598', '135_S_4722', '135_S_4723',\n",
      "       '135_S_5113', '137_S_0301', '137_S_0668', '137_S_0722',\n",
      "       '137_S_0800', '137_S_0972', '137_S_0994', '137_S_1414',\n",
      "       '137_S_4351', '137_S_4466', '137_S_4482', '137_S_4520',\n",
      "       '137_S_4587', '137_S_4631', '137_S_4632', '141_S_0767',\n",
      "       '141_S_0915', '141_S_1004', '141_S_1052', '141_S_6041',\n",
      "       '153_S_4125', '153_S_4139', '153_S_4151', '153_S_4372',\n",
      "       '941_S_1195', '941_S_1202', '941_S_1203', '941_S_4066',\n",
      "       '941_S_4100', '941_S_4255', '941_S_4292', '941_S_4365',\n",
      "       '941_S_4376'], dtype=object), array([ 2,  2,  4,  7,  6,  8,  6,  4,  4,  8,  6,  2, 42, 35, 22, 39, 23,\n",
      "        8, 24, 22, 12, 12,  9,  8,  8,  6,  9,  2,  5,  6,  8,  6,  8,  7,\n",
      "        7,  6,  1,  2, 10,  6,  6, 12,  8, 12,  4, 13,  2,  1,  2,  8,  7,\n",
      "       10,  9,  4, 28, 35, 35,  4,  7, 35,  5,  8,  6,  5,  9,  9, 22,  6,\n",
      "        6,  8,  8,  7,  9,  5,  7, 11,  7, 29, 19, 10, 20, 23, 34, 38, 37,\n",
      "       43,  8, 44, 29, 28, 29, 48, 16, 37, 25, 42, 11, 12,  8, 11,  8,  7,\n",
      "       21, 11, 21,  7, 28,  8,  2,  2,  2,  5,  8,  8,  5,  8,  8,  5, 26,\n",
      "       35, 45, 34, 23, 23, 28,  8,  4,  5, 12,  6, 20, 15, 11, 20, 13, 13,\n",
      "       10, 15, 20, 20,  9,  8,  9,  8,  7,  6,  1,  9,  9,  1,  1,  2,  4,\n",
      "        2, 17,  2,  4,  2, 30,  6, 30,  4, 21, 11,  6, 10,  7,  9,  2,  2,\n",
      "        6, 15,  7, 13, 10,  8,  8, 10,  9,  3, 40, 21, 37, 35,  7, 15, 17,\n",
      "        2,  2,  3,  3, 35, 37,  2,  1,  4,  6,  6,  7,  6,  7,  6,  8,  8,\n",
      "        3,  6,  6,  7, 10,  7,  8,  8,  9,  5,  6,  6,  6, 34, 18, 14,  8,\n",
      "        6,  8,  8,  6, 19, 22, 28,  8,  8,  6,  9,  7,  6,  3,  4,  4,  7,\n",
      "        5,  5,  7,  1,  3, 12, 16, 28,  7, 16, 25,  7,  9,  8,  8,  7,  7,\n",
      "       12,  9, 23,  7,  6, 28, 28, 14, 25,  6,  5,  6,  6,  4, 14, 14,  5,\n",
      "       12,  8,  8, 11,  3, 12,  8,  3,  2,  1,  2,  3,  5, 32, 23, 12, 25,\n",
      "        9, 13, 16, 11, 12, 22, 16, 17, 11, 17, 12, 24, 12, 10, 12,  8,  9,\n",
      "       12, 12,  8,  4,  7,  4,  6,  3,  6,  6, 13,  9,  8,  7,  8, 10,  4,\n",
      "        1,  2,  2,  5,  1,  9,  4,  7,  7,  5,  3,  2,  2,  7,  9,  6,  8,\n",
      "        9]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset size: {len(dataset)}\\n\")\n",
    "\n",
    "labels = [dataset[index]['research_group'] for index in range(len(dataset.subject_list))]\n",
    "\n",
    "ids = [dataset.subject_list[index].subject_metadata['Subject'] for index in range(len(dataset.subject_list))]\n",
    "\n",
    "print(f\"Unique labels: {np.unique(labels, return_counts=True)}\\n\")\n",
    "\n",
    "print(f\"Unique ids: {np.unique(ids, return_counts=True)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loader config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data, test_data = split_dataset(dataset, test_size=test_size, prevent_id_leakage=prevent_id_leakage)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn([data_string, labels_string]))\n",
    "\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn([data_string, labels_string]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data checks\n",
    "Check if there are subjects split across train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id intersection between train and test: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_ids = [dataset.subject_list[index].subject_metadata['Subject'].iloc[0] for index in train_data.indices]\n",
    "\n",
    "test_ids = [dataset.subject_list[index].subject_metadata['Subject'].iloc[0] for index in test_data.indices]\n",
    "\n",
    "print(f\"Id intersection between train and test: {np.intersect1d(np.unique(train_ids), np.unique(test_ids))}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([0])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][data_string].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/175 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4D (unbatched) or 5D (batched) input to conv3d, but got input of size: [16, 1, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m points \u001b[38;5;241m=\u001b[39m points\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Calculate loss, trans_feat argument as None as not used in this function\u001b[39;00m\n\u001b[1;32m     65\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, labels)\n",
      "File \u001b[0;32m/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/cnn3d_xmuyzz/ResNetV2.py:196\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 196\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m    198\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:725\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:720\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    710\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    719\u001b[0m     )\n\u001b[0;32m--> 720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4D (unbatched) or 5D (batched) input to conv3d, but got input of size: [16, 1, 0]"
     ]
    }
   ],
   "source": [
    "import cnn3d_xmuyzz.ResNetV2\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    \"training_losses\" : [],\n",
    "    \"validation_losses\": [],\n",
    "    \"conf_matrices\": [],\n",
    "    \"accuracies\": [],\n",
    "    \"f1s\": [],\n",
    "    \"precisions\": [],\n",
    "    \"recalls\": [],\n",
    "    \"train_time\": None,\n",
    "    \"num_training_images\": None\n",
    "}\n",
    "\n",
    "model = cnn3d_xmuyzz.ResNetV2.generate_model(\n",
    "            model_depth=18,\n",
    "            n_classes=2,\n",
    "            n_input_channels=1,\n",
    "            shortcut_type='B',\n",
    "            conv1_t_size=7,\n",
    "            conv1_t_stride=1,\n",
    "            no_max_pool=False,\n",
    "            widen_factor=1.0)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=0.001,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-08,\n",
    "            weight_decay=1e-4,\n",
    "            amsgrad=True\n",
    "        )\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    print(f\"Starting epoch {epoch + 1}\\n\")\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, dict in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "        \n",
    "        # Access dict returned by dataset __getitem__\n",
    "        points = dict[data_string]\n",
    "        labels = dict[labels_string]\n",
    "        \n",
    "        points, labels = points.to(device), labels.to(device)\n",
    "        \n",
    "        # Transform to have redundant channel of dimension 1 for model\n",
    "        points = points.unsqueeze(1)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(points)\n",
    "\n",
    "        # Calculate loss, trans_feat argument as None as not used in this function\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Multiply loss by batch size to account for differences in batch size (e.g last batch)\n",
    "        running_loss += loss.item() * points.size(0)\n",
    "        \n",
    "    metrics['training_losses'].append(running_loss/len(train_dataloader))\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialise loop metrics\n",
    "    running_loss = 0.0; conf_matrix = BinaryConfusionMatrix(); accuracy = BinaryAccuracy(); f1 = BinaryF1Score(); precision = BinaryPrecision(); recall = BinaryRecall()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch_idx, dict in enumerate(test_dataloader):\n",
    "            \n",
    "            points = dict[data_string]\n",
    "            labels = dict[labels_string]\n",
    "                     \n",
    "            points, labels = points.to(device), labels.to(device)\n",
    "            \n",
    "            # Transform to have redundant channel of dimension 1 for model\n",
    "            points = points.unsqueeze(1)\n",
    "            \n",
    "            output = model(points)\n",
    "            \n",
    "            running_loss += criterion(output, labels).item() * points.size(0)\n",
    "            \n",
    "            # Apply exponent as the output of the model is log softmax\n",
    "            pred_probability = torch.exp(output)\n",
    "            \n",
    "            # Threshold is variable to give preference to FN or FP\n",
    "            pred_labels = (pred_probability[:, 1] >= threshold).int()\n",
    "            \n",
    "            # Old label conversion\n",
    "            # pred_labels = torch.argmax(pred_probability, dim=-1)\n",
    "\n",
    "            # Update metrics\n",
    "            [metric.update(pred_labels, labels) for metric in [conf_matrix, accuracy, f1, precision, recall]]\n",
    "\n",
    "    end_time = datetime.now()\n",
    "            \n",
    "    # Append metric lists\n",
    "    [metrics[key].append(metric.compute()) for key, metric in [(\"conf_matrices\", conf_matrix), (\"accuracies\", accuracy), (\"f1s\", f1), (\"precisions\", precision), (\"recalls\", recall)]]       \n",
    "         \n",
    "    metrics['validation_losses'].append(running_loss/len(test_dataloader))\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch + 1} complete\\n\")\n",
    "    print(\"------------------------\")\n",
    "    print(conf_matrix.compute())\n",
    "    print(f\"Training Loss:   {metrics['training_losses'][-1]:.4f}\")\n",
    "    print(f\"Validation Loss: {metrics['validation_losses'][-1]:.4f}\")\n",
    "    print(f\"Accuracy:        {metrics['accuracies'][-1]:.4f}\")\n",
    "    print(f\"F1 Score:        {metrics['f1s'][-1]:.4f}\")\n",
    "    print(f\"Precision:       {metrics['precisions'][-1]:.4f}\")\n",
    "    print(f\"Recall:          {metrics['recalls'][-1]:.4f}\")\n",
    "    print(\"------------------------\\n\\n\")\n",
    "        \n",
    "    # Break before nightly restart\n",
    "    current_time = datetime.now()\n",
    "    \n",
    "    if current_time.hour == 23 and current_time.minute >= 30:\n",
    "        \n",
    "        print(\"Break before nightly restart\")\n",
    "        \n",
    "        break\n",
    "    \n",
    "metrics['train_time'] = end_time - start_time\n",
    "metrics['num_training_images'] = len(test_data)\n",
    "\n",
    "torch.save(model.state_dict(), 'trained_model.pth')\n",
    "\n",
    "print(\"Training complete and model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB this function has to remain in the notebook for it to work properly\n",
    "# Plot training loss, validation loss, and accuracy on separate subplots, along with displaying hyperparameters\n",
    "def plot(metrics, model_name, param_list, save=True, ylim=None):\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10), sharex=True)\n",
    "\n",
    "    ax1.plot(metrics['training_losses'], label='Training Loss', color='blue')\n",
    "    ax1.plot(metrics['validation_losses'], label='Validation Loss', color='red')\n",
    "    ax1.set_title('Training and Validation Loss over Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    \n",
    "    if ylim is not None:\n",
    "        \n",
    "        ax1.set_ylim(ylim)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        ax1.set_ylim(0, metrics['training_losses'][0] + 5)\n",
    "        \n",
    "    ax1.grid(True)\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    \n",
    "    ax2.plot(metrics['accuracies'], label='Accuracy', color='green')\n",
    "    ax2.plot(metrics['f1s'], label='F1 Score', color='blue')\n",
    "    ax2.plot(metrics['precisions'], label='Precision', color='red')\n",
    "    ax2.plot(metrics['recalls'], label='Recall', color='orange')\n",
    "    ax2.set_title('Metrics over epochs')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Value')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    ax2.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    \n",
    "    minutes = metrics['train_time'].seconds // 60\n",
    "\n",
    "    seconds = metrics['train_time'].seconds % 60\n",
    "\n",
    "    train_time_str = f\"Training time: {minutes:02d}m {seconds:02d}s\"\n",
    "\n",
    "    info = []\n",
    "    info.append(train_time_str)\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        info.append(f\"Number of training images: {metrics['num_training_images']:.0f}\")\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        print(\"Error with num_training_images\")\n",
    "        \n",
    "        \n",
    "    info.append(f\"Model name: {model_name}\")\n",
    "    info.append(f\"Best accuracy: {max(metrics['accuracies']):.2f}\")\n",
    "    info.append(f\"Best F1 Score: {max(metrics['f1s']):.2f}\")\n",
    "    info.append(f\"Best Precision: {max(metrics['precisions']):.2f}\")\n",
    "    info.append(f\"Best Recall: {max(metrics['recalls']):.2f}\")\n",
    "    info.append(f\"Epoch with smallest validation loss: {metrics['validation_losses'].index(min(metrics['validation_losses'])):.0f}\")\n",
    "    info.append(\"\\n\\n\")\n",
    "\n",
    "    # Nasty hack using globals() to get variable names automatically\n",
    "    for param in param_list:\n",
    "        \n",
    "        for name, value in globals().items():\n",
    "            \n",
    "            if value is param and name not in [info_line.split(\":\")[0] for info_line in info]:\n",
    "                \n",
    "                info.append(f\"{name}: {value}\")\n",
    "    \n",
    "    info_text = \"\\n\".join(info)\n",
    "    \n",
    "    fig.text(0.5, 0.02, info_text, ha='center', va='top', wrap=True, fontsize=10)\n",
    "\n",
    "    if save:\n",
    "        \n",
    "        # Save the fig and the lists of values\n",
    "        current_time = datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "        \n",
    "        name = f\"plot_{current_time}\"\n",
    "        \n",
    "        with open(f'/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/figs/{name}.pkl', 'wb') as file:\n",
    "            \n",
    "            pickle.dump(metrics, file)\n",
    "        \n",
    "        plt.savefig(f'/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/figs/{name}.png', bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot(metrics, \"ResNetV2\", [selected_labels, data_string, labels_string, downsample_majority, single_img_per_subject, prevent_id_leakage, batch_size, test_size, learning_rate, num_epochs, threshold])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
