{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from tqdm import tqdm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from final_models_explainability.get_predictions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/scratch-disk/full-datasets/hcampus-1.5T-cohort-holdout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = find_subjects_parallel(data_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subject_list:\n",
    "\n",
    "    subject.data = {}\n",
    "\n",
    "    # Group\n",
    "    mapping = {\n",
    "        'CN': 0,\n",
    "        'MCI': 1,\n",
    "    }\n",
    "\n",
    "    # Get the value of the mapping, -1 if not found\n",
    "    subject.data['research_group'] = mapping.get(subject.subject_metadata['Research Group'].iloc[0], -1)\n",
    "\n",
    "    # Cloud\n",
    "    subject.data['lhcampus_pointcloud_aligned'] = np.load(os.path.join(subject.path, 'Left-Hippocampus_aligned_cropped_mesh_downsampledcloud.npy'))\n",
    "    \n",
    "    # LR cloud\n",
    "    subject.data['hcampus_pointcloud_aligned'] = np.load(os.path.join(subject.path, 'Left-Hippocampus_Right-Hippocampus_aligned_cropped_mesh_downsampledcloud.npy'))\n",
    "\n",
    "    # Volumes\n",
    "    volume_col = subject.aseg_stats['Volume_mm3']\n",
    "    volume_col_normalised = volume_col / volume_col.sum() * 1000\n",
    "    struct_name_col = subject.aseg_stats['StructName']\n",
    "    \n",
    "    subject.data['volumes'] = np.array(volume_col_normalised)\n",
    "    \n",
    "    subject.data['struct_names'] = np.array(struct_name_col)\n",
    "\n",
    "    # Scores\n",
    "    mmse = subject.subject_metadata['MMSE Total Score'].iloc[0]\n",
    "    gdscale = subject.subject_metadata['GDSCALE Total Score'].iloc[0]\n",
    "    faq = subject.subject_metadata['FAQ Total Score'].iloc[0]\n",
    "    npiq = subject.subject_metadata['NPI-Q Total Score'].iloc[0]\n",
    "\n",
    "    subject.data['scores'] = [mmse, gdscale, faq, npiq]\n",
    "\n",
    "    subject.data['score_names'] = ['MMSE Total Score', 'GDSCALE Total Score', 'FAQ Total Score', 'NPI-Q Total Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total holdout subjects: {len(subject_list)}\\n\")\n",
    "print(f\"Total CN: {len([subject.data['research_group'] for subject in subject_list if subject.data['research_group'] == 0])}\\n\")\n",
    "print(f\"Total MCI: {len([subject.data['research_group'] for subject in subject_list if subject.data['research_group'] == 1])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate pointnet\n",
    "\n",
    "### Production pointnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "pred_probs = []\n",
    "pred_classes = []\n",
    "data = []\n",
    "attributions_zero_list = []\n",
    "attributions_mean_list = []\n",
    "\n",
    "# Run multiple times to account for randomness\n",
    "for i in range(5):\n",
    "\n",
    "    for subject in tqdm(subject_list, total=len(subject_list)):\n",
    "\n",
    "        pred_class, output, attributions_zero = get_pointnet_prediction(subject.data['lhcampus_pointcloud_aligned'], 'cuda')\n",
    "\n",
    "        data.append(subject.data['lhcampus_pointcloud_aligned'])\n",
    "\n",
    "        # Manually run attributions again for mean baseline attributions\n",
    "        model = pointnet2_cls_msg.get_model(2, normal_channel=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(\"final_models_explainability/pointnet.pth\", weights_only=True))\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        model.to('cuda')\n",
    "\n",
    "        input = torch.from_numpy(subject.data['lhcampus_pointcloud_aligned']).type(torch.float32).to('cuda')\n",
    "\n",
    "        attributions_mean = explain_pointnet(model, input, mode='mean')\n",
    "\n",
    "        attributions_mean_list.append(attributions_mean)\n",
    "\n",
    "        attributions_zero_list.append(attributions_zero)\n",
    "\n",
    "        true.append(subject.data['research_group'])\n",
    "        \n",
    "        pred_probs.append(output)\n",
    "\n",
    "        pred_classes.append(pred_class)\n",
    "\n",
    "np.savez('/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/pointnet_eval.npz', true=true, pred_probs=pred_probs, pred_classes=pred_classes, data=data, attributions_zero_list=attributions_zero_list, attributions_mean_list=attributions_mean_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.load('pointnet_eval.npz')\n",
    "true = results['true']\n",
    "pred_probs = results['pred_probs']\n",
    "pred_classes= results['pred_classes']\n",
    "data= results['data']\n",
    "attributions_list= results['attributions_list']\n",
    "\n",
    "\n",
    "report = classification_report(true, pred_classes, target_names=['CN', 'MCI'])\n",
    "\n",
    "print(report)\n",
    "\n",
    "roc_auc = roc_auc_score(true, pred_classes)\n",
    "\n",
    "print(f\"roc_auc: {roc_auc}\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(true, pred_probs)\n",
    "\n",
    "conf_matrix = confusion_matrix(true, pred_classes)\n",
    "\n",
    "conf_matrix_disp = ConfusionMatrixDisplay(conf_matrix, display_labels=['CN','MCI'])\n",
    "\n",
    "conf_matrix_disp.plot()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(fpr, tpr, color='purple')\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "ax.set_title('ROC Curve from final epoch')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_xlim(-0.01,1.01)\n",
    "ax.set_ylim(-0.01,1.01)\n",
    "ax.grid(True)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=False))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR pointnet for purposes of evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "pred_probs = []\n",
    "pred_classes = []\n",
    "data = []\n",
    "attributions_zero_list = []\n",
    "attributions_mean_list = []\n",
    "\n",
    "# Run multiple times to account for randomness\n",
    "for i in range(5):\n",
    "\n",
    "    for subject in tqdm(subject_list, total=len(subject_list)):\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            model = pointnet2_cls_msg.get_model(2, normal_channel=False)\n",
    "\n",
    "            model.load_state_dict(torch.load(\"lr_pointnet_eval.pth\", weights_only=True))\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            model.to('cuda')\n",
    "\n",
    "            input = subject.data['hcampus_pointcloud_aligned']\n",
    "\n",
    "            input = torch.from_numpy(input).type(torch.float32).to('cuda')\n",
    "\n",
    "            attributions_zero = explain_pointnet(model, input, mode='zero')\n",
    "\n",
    "            attributions_mean = explain_pointnet(model, input, mode='mean')\n",
    "\n",
    "            # Add batch dim and transpose to 3 x n for pointnet\n",
    "            input = input.unsqueeze(0).transpose(2, 1)\n",
    "\n",
    "            # Get output from model, ignoring extra info from pointnet\n",
    "            output = model(input)[0]\n",
    "\n",
    "            output = output.squeeze(0)\n",
    "\n",
    "            # Take negative logits and get probability\n",
    "            output = torch.nn.functional.softmax(output, dim=0)\n",
    "\n",
    "            pred_class = int(np.argmax(output.cpu().numpy()))\n",
    "\n",
    "            output = output.cpu().numpy()\n",
    "\n",
    "            # Get only the positive class as they add up to 1 anyway\n",
    "            output = output[1]\n",
    "\n",
    "            data.append(subject.data['hcampus_pointcloud_aligned'])\n",
    "\n",
    "            attributions_zero_list.append(attributions_zero)\n",
    "\n",
    "            attributions_mean_list.append(attributions_mean)\n",
    "\n",
    "            true.append(subject.data['research_group'])\n",
    "            \n",
    "            pred_probs.append(output)\n",
    "\n",
    "            pred_classes.append(pred_class)\n",
    "\n",
    "np.savez('/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/lr_pointnet_eval.npz', true=true, pred_probs=pred_probs, pred_classes=pred_classes, data=data, attributions_zero_list=attributions_zero_list, attributions_mean_list=attributions_mean_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.load('pointnet_eval.npz')\n",
    "true = results['true']\n",
    "pred_probs = results['pred_probs']\n",
    "pred_classes= results['pred_classes']\n",
    "data= results['data']\n",
    "attributions_list= results['attributions_list']\n",
    "\n",
    "\n",
    "report = classification_report(true, pred_classes, target_names=['CN', 'MCI'])\n",
    "\n",
    "print(report)\n",
    "\n",
    "roc_auc = roc_auc_score(true, pred_classes)\n",
    "\n",
    "print(f\"roc_auc: {roc_auc}\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(true, pred_probs)\n",
    "\n",
    "conf_matrix = confusion_matrix(true, pred_classes)\n",
    "\n",
    "conf_matrix_disp = ConfusionMatrixDisplay(conf_matrix, display_labels=['CN','MCI'])\n",
    "\n",
    "conf_matrix_disp.plot()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(fpr, tpr, color='purple')\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "ax.set_title('ROC Curve from final epoch')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_xlim(-0.01,1.01)\n",
    "ax.set_ylim(-0.01,1.01)\n",
    "ax.grid(True)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=False))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate volumes gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "pred_probs = []\n",
    "pred_classes = []\n",
    "data = []\n",
    "\n",
    "for subject in subject_list:\n",
    "\n",
    "    pred_class, output, _ = get_volumes_prediction(subject.data['volumes'])\n",
    "\n",
    "    data.append(subject.data['volumes'])\n",
    "\n",
    "    true.append(subject.data['research_group'])\n",
    "    \n",
    "    pred_probs.append(output)\n",
    "\n",
    "    pred_classes.append(pred_class)\n",
    "\n",
    "np.savez('/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/volumes_eval.npz', true=true, pred_probs=pred_probs, pred_classes=pred_classes, data=data, attributions_list=attributions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.load('volumes_eval.npz')\n",
    "true = results['true']\n",
    "pred_probs = results['pred_probs']\n",
    "pred_classes= results['pred_classes']\n",
    "data= results['data']\n",
    "attributions_list= results['attributions_list']\n",
    "\n",
    "report = classification_report(true, pred_classes, target_names=['CN', 'MCI'])\n",
    "\n",
    "print(report)\n",
    "\n",
    "roc_auc = roc_auc_score(true, pred_classes)\n",
    "\n",
    "print(f\"roc_auc: {roc_auc}\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(true, pred_probs)\n",
    "\n",
    "conf_matrix = confusion_matrix(true, pred_classes)\n",
    "\n",
    "conf_matrix_disp = ConfusionMatrixDisplay(conf_matrix, display_labels=['CN','MCI'])\n",
    "\n",
    "conf_matrix_disp.plot()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate scores gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "pred_probs = []\n",
    "pred_classes = []\n",
    "data = []\n",
    "\n",
    "for subject in subject_list:\n",
    "\n",
    "    pred_class, output = get_scores_prediction(subject.data['scores'])\n",
    "\n",
    "    data.append(subject.data['scores'])\n",
    "\n",
    "    true.append(subject.data['research_group'])\n",
    "    \n",
    "    pred_probs.append(output)\n",
    "\n",
    "    pred_classes.append(pred_class)\n",
    "\n",
    "np.savez('/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/scores_eval.npz', true=true, pred_probs=pred_probs, pred_classes=pred_classes, data=data, attributions_list=attributions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.load('scores_eval.npz')\n",
    "true = results['true']\n",
    "pred_probs = results['pred_probs']\n",
    "pred_classes= results['pred_classes']\n",
    "data= results['data']\n",
    "attributions_list= results['attributions_list']\n",
    "\n",
    "report = classification_report(true, pred_classes, target_names=['CN', 'MCI'])\n",
    "\n",
    "print(report)\n",
    "\n",
    "roc_auc = roc_auc_score(true, pred_classes)\n",
    "\n",
    "print(f\"roc_auc: {roc_auc}\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(true, pred_probs)\n",
    "\n",
    "conf_matrix = confusion_matrix(true, pred_classes)\n",
    "\n",
    "conf_matrix_disp = ConfusionMatrixDisplay(conf_matrix, display_labels=['CN','MCI'])\n",
    "\n",
    "conf_matrix_disp.plot()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(fpr, tpr, color='purple')\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "ax.set_title('ROC Curve from final epoch')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_xlim(-0.01,1.01)\n",
    "ax.set_ylim(-0.01,1.01)\n",
    "ax.grid(True)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=False))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate averave ensemble without scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "pred_probs = []\n",
    "pred_classes = []\n",
    "data = []\n",
    "\n",
    "# Run multiple times to account for randomness\n",
    "for i in range(5):\n",
    "\n",
    "    for subject in tqdm(subject_list, total=len(subject_list)):\n",
    "\n",
    "        pointnet_pred_class, pointnet_output, attributions = get_pointnet_prediction(subject.data['lhcampus_pointcloud_aligned'], 'cuda')\n",
    "\n",
    "        volumes_pred_class, volumes_output, shap_values = get_volumes_prediction(subject.data['volumes'], subject.data['struct_names'])\n",
    "\n",
    "        pred_class, output = get_ensemble_prediction_avg(pointnet_output, volumes_output, None, scores=False)\n",
    "\n",
    "        data.append(subject.data['volumes'])\n",
    "\n",
    "        true.append(subject.data['research_group'])\n",
    "        \n",
    "        pred_probs.append(output)\n",
    "\n",
    "        pred_classes.append(pred_class)\n",
    "\n",
    "np.savez('/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/avgensemblenoscores_eval.npz', true=true, pred_probs=pred_probs, pred_classes=pred_classes, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.load('avgensemble_eval.npz')\n",
    "true = results['true']\n",
    "pred_probs = results['pred_probs']\n",
    "pred_classes= results['pred_classes']\n",
    "data= results['data']\n",
    "attributions_list= results['attributions_list']\n",
    "\n",
    "report = classification_report(true, pred_classes, target_names=['CN', 'MCI'])\n",
    "\n",
    "print(report)\n",
    "\n",
    "roc_auc = roc_auc_score(true, pred_classes)\n",
    "\n",
    "print(f\"roc_auc: {roc_auc}\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(true, pred_probs)\n",
    "\n",
    "conf_matrix = confusion_matrix(true, pred_classes)\n",
    "\n",
    "conf_matrix_disp = ConfusionMatrixDisplay(conf_matrix, display_labels=['CN','MCI'])\n",
    "\n",
    "conf_matrix_disp.plot()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(fpr, tpr, color='purple')\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "ax.set_title('ROC Curve from final epoch')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_xlim(-0.01,1.01)\n",
    "ax.set_ylim(-0.01,1.01)\n",
    "ax.grid(True)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=False))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate maxprob ensemble without scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "pred_probs = []\n",
    "pred_classes = []\n",
    "data = []\n",
    "models_used = []\n",
    "\n",
    "# Run multiple times to account for randomness\n",
    "for i in range(5):\n",
    "\n",
    "    for subject in tqdm(subject_list, total=len(subject_list)):\n",
    "\n",
    "        pointnet_pred_class, pointnet_output, attributions = get_pointnet_prediction(subject.data['lhcampus_pointcloud_aligned'], 'cuda')\n",
    "\n",
    "        volumes_pred_class, volumes_output, shap_values = get_volumes_prediction(subject.data['volumes'], subject.data['struct_names'])\n",
    "\n",
    "        pred_class, output, index = get_ensemble_prediction_maxprob((pointnet_pred_class, pointnet_output), (volumes_pred_class, volumes_output), None, scores=False)\n",
    "\n",
    "        models_used.append(index)\n",
    "\n",
    "        data.append(subject.data['volumes'])\n",
    "\n",
    "        true.append(subject.data['research_group'])\n",
    "        \n",
    "        pred_probs.append(output)\n",
    "\n",
    "        pred_classes.append(pred_class)\n",
    "\n",
    "print(np.unique(models_used, return_counts=True))\n",
    "\n",
    "np.savez('/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/maxprobensemblenoscores_eval.npz', true=true, pred_probs=pred_probs, pred_classes=pred_classes, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.load('maxprobensemble_eval.npz')\n",
    "true = results['true']\n",
    "pred_probs = results['pred_probs']\n",
    "pred_classes= results['pred_classes']\n",
    "data= results['data']\n",
    "\n",
    "report = classification_report(true, pred_classes, target_names=['CN', 'MCI'])\n",
    "\n",
    "print(report)\n",
    "\n",
    "roc_auc = roc_auc_score(true, pred_classes)\n",
    "\n",
    "print(f\"roc_auc: {roc_auc}\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(true, pred_probs)\n",
    "\n",
    "conf_matrix = confusion_matrix(true, pred_classes)\n",
    "\n",
    "conf_matrix_disp = ConfusionMatrixDisplay(conf_matrix, display_labels=['CN','MCI'])\n",
    "\n",
    "conf_matrix_disp.plot()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(fpr, tpr, color='purple')\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "ax.set_title('ROC Curve from final epoch')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_xlim(-0.01,1.01)\n",
    "ax.set_ylim(-0.01,1.01)\n",
    "ax.grid(True)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=False))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate averave ensemble with scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "pred_probs = []\n",
    "pred_classes = []\n",
    "data = []\n",
    "\n",
    "# Run multiple times to account for randomness\n",
    "for i in range(5):\n",
    "\n",
    "    for subject in tqdm(subject_list, total=len(subject_list)):\n",
    "\n",
    "        pointnet_pred_class, pointnet_output, attributions = get_pointnet_prediction(subject.data['lhcampus_pointcloud_aligned'], 'cuda')\n",
    "\n",
    "        volumes_pred_class, volumes_output, shap_values = get_volumes_prediction(subject.data['volumes'], subject.data['struct_names'])\n",
    "\n",
    "        scores_pred_class, scores_output = get_scores_prediction(subject.data['scores'])\n",
    "\n",
    "        pred_class, output = get_ensemble_prediction_avg(pointnet_output, volumes_output, scores_output, scores=True)\n",
    "\n",
    "        data.append(subject.data['volumes'])\n",
    "\n",
    "        true.append(subject.data['research_group'])\n",
    "        \n",
    "        pred_probs.append(output)\n",
    "\n",
    "        pred_classes.append(pred_class)\n",
    "\n",
    "np.savez('/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/avgensemble_eval.npz', true=true, pred_probs=pred_probs, pred_classes=pred_classes, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.load('avgensemble_eval.npz')\n",
    "true = results['true']\n",
    "pred_probs = results['pred_probs']\n",
    "pred_classes= results['pred_classes']\n",
    "data= results['data']\n",
    "\n",
    "report = classification_report(true, pred_classes, target_names=['CN', 'MCI'])\n",
    "\n",
    "print(report)\n",
    "\n",
    "roc_auc = roc_auc_score(true, pred_classes)\n",
    "\n",
    "print(f\"roc_auc: {roc_auc}\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(true, pred_probs)\n",
    "\n",
    "conf_matrix = confusion_matrix(true, pred_classes)\n",
    "\n",
    "conf_matrix_disp = ConfusionMatrixDisplay(conf_matrix, display_labels=['CN','MCI'])\n",
    "\n",
    "conf_matrix_disp.plot()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(fpr, tpr, color='purple')\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "ax.set_title('ROC Curve from final epoch')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_xlim(-0.01,1.01)\n",
    "ax.set_ylim(-0.01,1.01)\n",
    "ax.grid(True)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=False))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate maxprob ensemble with scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "pred_probs = []\n",
    "pred_classes = []\n",
    "data = []\n",
    "models_used = []\n",
    "\n",
    "# Run multiple times to account for randomness\n",
    "for i in range(5):\n",
    "\n",
    "    for subject in tqdm(subject_list, total=len(subject_list)):\n",
    "\n",
    "        pointnet_pred_class, pointnet_output, attributions = get_pointnet_prediction(subject.data['lhcampus_pointcloud_aligned'], 'cuda')\n",
    "\n",
    "        volumes_pred_class, volumes_output, shap_values = get_volumes_prediction(subject.data['volumes'], subject.data['struct_names'])\n",
    "\n",
    "        scores_pred_class, scores_output = get_scores_prediction(subject.data['scores'])\n",
    "\n",
    "        pred_class, output, index = get_ensemble_prediction_maxprob((pointnet_pred_class, pointnet_output), (volumes_pred_class, volumes_output), (scores_pred_class, scores_output), scores=True)\n",
    "\n",
    "        models_used.append(index)\n",
    "\n",
    "        data.append(subject.data['volumes'])\n",
    "\n",
    "        true.append(subject.data['research_group'])\n",
    "        \n",
    "        pred_probs.append(output)\n",
    "\n",
    "        pred_classes.append(pred_class)\n",
    "\n",
    "print(np.unique(models_used, return_counts=True))\n",
    "\n",
    "np.savez('/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/maxprobensemble_eval.npz', true=true, pred_probs=pred_probs, pred_classes=pred_classes, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.load('maxprobensemble_eval.npz')\n",
    "true = results['true']\n",
    "pred_probs = results['pred_probs']\n",
    "pred_classes= results['pred_classes']\n",
    "data= results['data']\n",
    "\n",
    "report = classification_report(true, pred_classes, target_names=['CN', 'MCI'])\n",
    "\n",
    "print(report)\n",
    "\n",
    "roc_auc = roc_auc_score(true, pred_classes)\n",
    "\n",
    "print(f\"roc_auc: {roc_auc}\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(true, pred_probs)\n",
    "\n",
    "conf_matrix = confusion_matrix(true, pred_classes)\n",
    "\n",
    "conf_matrix_disp = ConfusionMatrixDisplay(conf_matrix, display_labels=['CN','MCI'])\n",
    "\n",
    "conf_matrix_disp.plot()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(fpr, tpr, color='purple')\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "ax.set_title('ROC Curve from final epoch')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_xlim(-0.01,1.01)\n",
    "ax.set_ylim(-0.01,1.01)\n",
    "ax.grid(True)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=False))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
