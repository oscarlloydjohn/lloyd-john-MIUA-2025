{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nibabel\n",
    "import nibabel.affines\n",
    "from PIL import Image\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import ants\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import xmltodict\n",
    "import shutil\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File handling and loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image into nibabel\n",
    "def load_image(data_path, filename):\n",
    "    \n",
    "    return nibabel.load(f\"{data_path}/{filename}\")\n",
    "\n",
    "# Display the middle slice of a nibabel image\n",
    "def display_image(image):\n",
    "\n",
    "    # Get image data array from image object\n",
    "    image_array = np.asarray(image.dataobj)\n",
    "    \n",
    "    display_array(image_array)\n",
    "    \n",
    "    return \n",
    "\n",
    "# Display the middle slice of a 3d array\n",
    "def display_array(array):\n",
    "    \n",
    "    # Get middle slice\n",
    "    slice = array[array.shape[0] // 2, :, :]\n",
    "    \n",
    "    # Scale the image such that the maximum pixel value is 255\n",
    "    # Display the scaled image\n",
    "    display(Image.fromarray(((slice / np.max(slice)) * 255).astype(np.uint8)))\n",
    "    \n",
    "    return \n",
    "\n",
    "def display_image_3d(image):\n",
    "    \n",
    "    # Get image data array from image object\n",
    "    image_array = np.asarray(image.dataobj)\n",
    "    \n",
    "    display_array_3d(image_array)\n",
    "    \n",
    "    return\n",
    "\n",
    "def display_array_3d(array):\n",
    "    \n",
    "    array = (array / np.max(array)) * 255\n",
    "\n",
    "    x, y, z = np.indices(array.shape)\n",
    "\n",
    "    \n",
    "    # Set up the plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    ax.voxels(x, y, z, array > 0, facecolors=plt.cm.viridis(array / 255.0), edgecolors='k')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return \n",
    "\n",
    "# Display the middle slice of a 3d array\n",
    "def display_array(array):\n",
    "    \n",
    "    # Get middle slice\n",
    "    slice = array[array.shape[0] // 2, :, :]\n",
    "    \n",
    "    # Scale the image such that the maximum pixel value is 255\n",
    "    # Display the scaled image\n",
    "    display(Image.fromarray(((slice / np.max(slice)) * 255).astype(np.uint8)))\n",
    "    \n",
    "    return \n",
    "\n",
    "# Find files with a specific filename and return a list. Non-recursive \n",
    "def list_files_ext(data_path, extensions):\n",
    "\n",
    "    files = [f for f in os.listdir(data_path) if f.endswith(extensions)]\n",
    "        \n",
    "    return files       \n",
    "\n",
    "# Return the absolute path to all files matching a filename in a directory. Recursive\n",
    "def list_files_fname(data_path, filename):\n",
    "    \n",
    "    matched_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        \n",
    "        for file in fnmatch.filter(files, filename):\n",
    "            \n",
    "            matched_files.append(os.path.join(root, file))\n",
    "    \n",
    "    return matched_files\n",
    "\n",
    "# Delete the files returned by list_files_fname\n",
    "def delete_file_matching(data_path, filename):\n",
    "    \n",
    "    for file in list_files_fname(data_path, filename):\n",
    "        \n",
    "        os.remove(file)\n",
    "    \n",
    "    return\n",
    "\n",
    "def delete_aux_files(subject):\n",
    "    \n",
    "    for file in subject.aux_file_list[:]:\n",
    "        \n",
    "            subject.aux_file_list.remove(file)\n",
    "        \n",
    "            os.remove(os.path.normpath(file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:27: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:27: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_19114/876710754.py:27: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  self.aseg_stats = pd.read_csv(os.path.join(path, 'stats/aseg+DKT.stats'), delimiter='\\s+', comment='#', header=None, names=header)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Subject:\n",
    "    \n",
    "    # Constructor assumes that the directory has already been processed in the specific format using fastsurfer\n",
    "    # See preprocess.py\n",
    "    def __init__(self, path):\n",
    "        \n",
    "        # Existing before object creation\n",
    "        self.path = path\n",
    "        \n",
    "        self.orig_nu = os.path.join(path, \"mri/orig_nu.mgz\")\n",
    "        \n",
    "        self.mask = os.path.join(path, \"mri/mask.mgz\")\n",
    "        \n",
    "        self.aparc = os.path.join(path, \"mri/aparc.DKTatlas+aseg.deep.mgz\")\n",
    "        \n",
    "        xml_files = glob.glob(os.path.join(path, \"*.xml\"))\n",
    "        \n",
    "        self.xml_path = xml_files[0] if xml_files else None\n",
    "        \n",
    "        with open(self.xml_path, 'r') as file:\n",
    "            \n",
    "                self.xml_df = xmltodict.parse(file.read())\n",
    "\n",
    "        # Manually assign the column headers\n",
    "        header = ['ColHeaders', 'Index', 'SegId', 'NVoxels', 'Volume_mm3', 'StructName', 'normMean', 'normStdDev', 'normMin', 'normMax', 'normRange']\n",
    "        \n",
    "        self.aseg_stats = pd.read_csv(os.path.join(path, 'stats/aseg+DKT.stats'), delimiter='\\s+', comment='#', header=None, names=header)\n",
    "        \n",
    "        # Existing after object creation\n",
    "        \n",
    "        # Affine aligned brain\n",
    "        brain_aligned = os.path.join(path, \"brain_aligned.nii\")\n",
    "        \n",
    "        self.brain_aligned = brain_aligned if os.path.isfile(brain_aligned) else None\n",
    "        \n",
    "        # Affine alignment matrix from ANTsPy\n",
    "        affine_alignment = os.path.join(path, 'affine_alignment.mat')\n",
    "        \n",
    "        self.affine_alignment = affine_alignment if os.path.isfile(affine_alignment) else None\n",
    "        \n",
    "        # Aparc file aligned with matrix\n",
    "        aparc_aligned = os.path.join(path, \"aparc.DKTatlas+aseg.deep_aligned.nii\")\n",
    "        \n",
    "        self.aparc_aligned = aparc_aligned if os.path.isfile(aparc_aligned) else None\n",
    "        \n",
    "        # Aligned and cropped brain\n",
    "        brain_aligned_cropped = os.path.join(path, \"brain_aligned_cropped.nii\")\n",
    "        \n",
    "        self.brain_aligned_cropped = brain_aligned_cropped if os.path.isfile(brain_aligned_cropped) else None\n",
    "        \n",
    "        # NB specific regions e.g hippocampus are not stored in the object. Access them using their path from the aux file list\n",
    "        \n",
    "        # Set of all files for convenience\n",
    "        self.aux_file_list = {f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))}\n",
    "        \n",
    "        \n",
    "# Searches data_path for subject directories and creates an object for each of them\n",
    "def find_subjects(data_path):\n",
    "    \n",
    "    subject_list = []\n",
    "\n",
    "    for item in os.listdir(data_path):\n",
    "        \n",
    "        subject_path = os.path.join(data_path, item)\n",
    "        \n",
    "        if os.path.isdir(subject_path):\n",
    "            \n",
    "            # MRI directory of subject path (checking validity)\n",
    "            mri_path = os.path.join(subject_path, 'mri')\n",
    "            \n",
    "            # Check for MRI directory\n",
    "            if os.path.isdir(mri_path):\n",
    "                \n",
    "                orig_file = os.path.join(mri_path, 'orig_nu.mgz')\n",
    "                \n",
    "                mask_file = os.path.join(mri_path, 'mask.mgz')\n",
    "\n",
    "                # If both orig.mgz and mask.mgz exist, create object\n",
    "                if os.path.isfile(orig_file) and os.path.isfile(mask_file):\n",
    "                    \n",
    "                    subject_list.append(Subject(subject_path))\n",
    "\n",
    "    return subject_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image manipulation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs brain extraction using the orig_nu.mgz and mask.mgz of the subject by multiplying the mask with the image\n",
    "def extract_brain(orig_file, mask_file):\n",
    "    \n",
    "    # Load the image and the brain mask\n",
    "    image = nibabel.load(orig_file)\n",
    "    mask = nibabel.load(mask_file)\n",
    "    \n",
    "    # Get their image arrays\n",
    "    image_array = np.asarray(image.dataobj)\n",
    "    mask_array = np.asarray(mask.dataobj)\n",
    "    \n",
    "    # Apply the mask, the mask entries are 1 or 0\n",
    "    brain_array = image_array * mask_array\n",
    "    \n",
    "    return brain_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference brain (global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB seems that fastsrufer brain is better\n",
    "reference_brain_array_mni = extract_brain(\"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/mni_icbm152_lin_nifti/icbm_avg_152_t1_tal_lin.nii\", \"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/mni_icbm152_lin_nifti/icbm_avg_152_t1_tal_lin_mask.nii\")\n",
    "\n",
    "display_array(reference_brain_array_mni)\n",
    "\n",
    "reference_brain_array_fastsurfer = extract_brain(\"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/mni_icbm152_lin_nifti/fastsurfer-processed/mri/orig_nu.mgz\", \"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/mni_icbm152_lin_nifti/fastsurfer-processed/mri/mask.mgz\")\n",
    "\n",
    "display_array(reference_brain_array_fastsurfer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine align a single subject\n",
    "def alignment(subject):\n",
    "        \n",
    "    # Extract brain of subject and convert it to an ANTsPy image\n",
    "    # The subject's brain is the moving image\n",
    "    brain_array = extract_brain(subject.orig_nu, subject.mask)\n",
    "    \n",
    "    moving_image = ants.from_numpy(brain_array)\n",
    "    \n",
    "    # Convert the reference brain to an ANTsPy image\n",
    "    # The reference brain is already extracted\n",
    "    fixed_image = ants.from_numpy(reference_brain_array_fastsurfer)\n",
    "    \n",
    "    # Perform registration using ANTsPy\n",
    "    registration = ants.registration(fixed=fixed_image, moving=moving_image, type_of_transform='AffineFast')\n",
    "    \n",
    "    aligned_brain_array = registration['warpedmovout'].numpy()\n",
    "    \n",
    "    # Copy the temp mat transformation file to the subject directory\n",
    "    shutil.copy(registration['fwdtransforms'][0], os.path.join(subject.path, 'affine_alignment.mat'))\n",
    "    \n",
    "    subject.affine_alignment = os.path.join(subject.path, 'affine_alignment.mat')\n",
    "    \n",
    "    # Make nibabel image from array\n",
    "    # Identity matrix as affine transform\n",
    "    aligned_image = nibabel.Nifti1Image(aligned_brain_array, np.eye(4))\n",
    "    \n",
    "    # Save the NiBabel image as a .nii file\n",
    "    aligned_image_path = os.path.join(subject.path, 'brain_aligned.nii')\n",
    "    \n",
    "    nibabel.save(aligned_image, aligned_image_path)\n",
    "    \n",
    "    subject.brain_aligned = aligned_image_path\n",
    "    \n",
    "    return aligned_image\n",
    "\n",
    "# Affine align a list of subjects in parallel \n",
    "def alignment_parallel(subject_list):\n",
    "        \n",
    "    # Use ProcessPoolExecutor to run affine alignment in parallel\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        \n",
    "        futures = []\n",
    "        \n",
    "        for subject in subject_list:\n",
    "\n",
    "            futures.append(executor.submit(alignment, subject))\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            \n",
    "            display_image(future.result())\n",
    "            \n",
    "    return\n",
    "\n",
    "\n",
    "# Uses affine_alignment.mat of a subject to align another file (for example the aseg file)\n",
    "# Must have already been aligned using \n",
    "def aux_alignment(subject, file, is_aparc):\n",
    "    \n",
    "    # Open both images\n",
    "    fixed_image = ants.from_numpy(np.asarray(nibabel.load(subject.brain_aligned).get_fdata()))\n",
    "    \n",
    "    moving_image = ants.from_numpy(np.asarray(nibabel.load(file).get_fdata()))\n",
    "    \n",
    "    # Must use nearest neighbours for interpolation to preserve discrete labels (colours), prevents blurring\n",
    "    transformed_image = ants.apply_transforms(fixed_image, moving_image, subject.affine_alignment, interpolator='nearestNeighbor')\n",
    "    \n",
    "    ants.plot(fixed_image)\n",
    "    \n",
    "    ants.plot(transformed_image)\n",
    "    \n",
    "    path = os.path.join(subject.path,(os.path.splitext(os.path.basename(file))[0] + '_aligned.nii'))\n",
    "    \n",
    "    \n",
    "    if is_aparc:\n",
    "        \n",
    "        # Convert to nibabel image\n",
    "        # Make sure parcellation files are stored as int as they contain discrete values\n",
    "        transformed_image = nibabel.Nifti1Image(transformed_image.numpy(), np.eye(4), dtype=np.int32)\n",
    "\n",
    "        nibabel.save(transformed_image, path)\n",
    "        \n",
    "        subject.aparc_aligned = path\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Convert to nibabel image\n",
    "        transformed_image = nibabel.Nifti1Image(transformed_image.numpy(), np.eye(4))\n",
    "\n",
    "        nibabel.save(transformed_image, path)\n",
    "        \n",
    "        subject.aux_file_list.add(path)\n",
    "        \n",
    "    \n",
    "    return transformed_image\n",
    "\n",
    "# Align aparc files in parallel\n",
    "def aux_alignment_parallel(subject_list):\n",
    "    \n",
    "    # Use ProcessPoolExecutor to run affine alignment in parallel\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        \n",
    "        futures = []\n",
    "        \n",
    "        for subject in subject_list:\n",
    "\n",
    "            futures.append(executor.submit(aux_alignment, subject, subject.aparc, True))\n",
    "            \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            \n",
    "            display_image(future.result())\n",
    "            \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop images to the minimum size whilst retaining whole dataset\n",
    "# Can only be done on the whole dataset as the dataset has to be checked before\n",
    "def crop_subjects(subject_list, relative_path, is_full_brain):\n",
    "    \n",
    "    max_bbox = (np.inf, np.inf, np.inf, -np.inf, -np.inf, -np.inf)\n",
    "    \n",
    "    def bounding_box(image_array):\n",
    "    \n",
    "        non_zero_indices = np.nonzero(image_array)\n",
    "        \n",
    "        min_x, min_y, min_z = np.min(non_zero_indices[0]), np.min(non_zero_indices[1]), np.min(non_zero_indices[2])\n",
    "        max_x, max_y, max_z = np.max(non_zero_indices[0]), np.max(non_zero_indices[1]), np.max(non_zero_indices[2])\n",
    "        \n",
    "        return (min_x, min_y, min_z, max_x, max_y, max_z)\n",
    "    \n",
    "    # Find maximum bbox\n",
    "    for subject in subject_list:\n",
    "    \n",
    "        image = nibabel.load(os.path.join(subject.path, relative_path))\n",
    "        \n",
    "        min_x, min_y, min_z, max_x, max_y, max_z = bounding_box(image.get_fdata())\n",
    "        \n",
    "        # Update max_bbox\n",
    "        max_bbox = (\n",
    "            min(max_bbox[0], min_x),\n",
    "            min(max_bbox[1], min_y),\n",
    "            min(max_bbox[2], min_z),\n",
    "            max(max_bbox[3], max_x),\n",
    "            max(max_bbox[4], max_y),\n",
    "            max(max_bbox[5], max_z)\n",
    "        )\n",
    "          \n",
    "          \n",
    "    for subject in subject_list:\n",
    "        \n",
    "        image = nibabel.load(os.path.join(subject.path, relative_path))\n",
    "        \n",
    "        image_array = image.get_fdata()\n",
    "        \n",
    "        global_min_x, global_min_y, global_min_z, global_max_x, global_max_y, global_max_z = max_bbox\n",
    "        \n",
    "        # Crop the image array using the global bounding box\n",
    "        cropped_array = image_array[\n",
    "            int(global_min_x):int(global_max_x),\n",
    "            int(global_min_y):int(global_max_y),\n",
    "            int(global_min_z):int(global_max_z)\n",
    "        ]\n",
    "        \n",
    "        # Create a new NiBabel image from the cropped array\n",
    "        cropped_image = nibabel.Nifti1Image(cropped_array, image.affine)\n",
    "        \n",
    "        display_image(cropped_image)\n",
    "        \n",
    "        fname = os.path.splitext(os.path.basename(relative_path))[0]\n",
    "                \n",
    "        cropped_path = os.path.join(subject.path,(fname + '_cropped.nii'))\n",
    "        \n",
    "        nibabel.save(cropped_image, cropped_path)\n",
    "        \n",
    "        if is_full_brain:\n",
    "            \n",
    "            subject.brain_aligned_cropped = cropped_path\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            subject.aux_file_list.add(cropped_path)\n",
    "\n",
    "            \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts brain regions using their number label found from freesurfer LUT\n",
    "# Takes regions as a name\n",
    "def extract_region(subject, values_list, brain, aparc, is_aligned):\n",
    "    \n",
    "    aparc_array = nibabel.load(aparc).get_fdata()\n",
    "    \n",
    "    image_array = nibabel.load(brain).get_fdata()\n",
    "    \n",
    "    # Create a mask from regions in list\n",
    "    filtered_array = np.where(np.isin(aparc_array, values_list), 1, 0)\n",
    "    \n",
    "    # Check for empty array\n",
    "    if np.all(filtered_array == 0):\n",
    "        \n",
    "        print(\"Error: region empty\")\n",
    "        \n",
    "        return filtered_array\n",
    "\n",
    "    \n",
    "    # Extract region using mask\n",
    "    extracted_region = image_array * filtered_array\n",
    "    \n",
    "    # Look up the name of the region for the filename\n",
    "    lut_path = \"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/preprocessing/FreeSurferColorLUT.txt\"\n",
    "    \n",
    "    lut = pd.read_csv(lut_path, delimiter='\\s+', comment='#', header=None)\n",
    "    \n",
    "    region_names = lut[lut[0].isin(values_list)][1]\n",
    "\n",
    "    # Save the regions as a nii file\n",
    "    region_image = nibabel.Nifti1Image(extracted_region, np.eye(4))\n",
    "    \n",
    "    if is_aligned:\n",
    "            \n",
    "        region_image_path = os.path.join(subject.path, ('_'.join(region_names) + '_aligned.nii'))\n",
    "        \n",
    "    else:\n",
    "            \n",
    "        region_image_path = os.path.join(subject.path, ('_'.join(region_names) + '.nii'))\n",
    "        \n",
    "    nibabel.save(region_image, region_image_path)\n",
    "        \n",
    "    subject.aux_file_list.append(region_image_path)\n",
    "    \n",
    "    return extracted_region\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(subject_list[0].aux_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''print(list_files_fname(data_path, 'aligned_brain.nii'))\n",
    "    \n",
    "delete_file_matching(data_path, 'aligned_brain.nii')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "'''pprint.pprint(list_files_fname(data_path, 'affine_alignment.pkl'))\n",
    "    \n",
    "delete_file_matching(data_path, 'affine_alignment.pkl')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''print(list_files_fname(data_path, 'aligned_brain_cropped.nii'))\n",
    "    \n",
    "delete_file_matching(data_path, 'aligned_brain_cropped.nii')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/scratch disk/full-datasets/adni1-complete-1yr-3t\"\n",
    "\n",
    "subject_list = find_subjects(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_parallel(subject_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_subjects(subject_list, 'brain_aligned.nii', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB affine alinged aparcs may be inaccurate\n",
    "aux_alignment_parallel(subject_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hippocampus from non-aligned brains (serial)\n",
    "for subject in subject_list:\n",
    "    \n",
    "    extract_region(subject, [17, 53], subject.orig_nu, subject.aparc, False)\n",
    "    \n",
    "    print('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crop hippocampi\n",
    "crop_subjects(subject_list, 'Left-Hippocampus_Right-Hippocampus.nii', False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Subject' object has no attribute 'aparc_aligned'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract hippocampus from aligned brains (serial)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subject \u001b[38;5;129;01min\u001b[39;00m subject_list:\n\u001b[0;32m----> 4\u001b[0m     extract_region(subject, [\u001b[38;5;241m17\u001b[39m, \u001b[38;5;241m53\u001b[39m], subject\u001b[38;5;241m.\u001b[39mbrain_aligned, \u001b[43msubject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maparc_aligned\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Subject' object has no attribute 'aparc_aligned'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract hippocampus from aligned brains (serial)\n",
    "for subject in subject_list:\n",
    "    \n",
    "    extract_region(subject, [17, 53], subject.brain_aligned, subject.aparc_aligned, True)\n",
    "    \n",
    "    print('.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crop hippocampi\n",
    "crop_subjects(subject_list, 'Left-Hippocampus_Right-Hippocampus_aligned.nii')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "for subject in subject_list:\n",
    "    \n",
    "    research_group = subject.xml_df['idaxs']['project']['subject']['researchGroup']\n",
    "    \n",
    "    print(subject.xml_df['idaxs']['project']['subject'])\n",
    "    \n",
    "    #print(research_group)\n",
    "    \n",
    "    display_image(nibabel.load(subject.brain_aligned_cropped))\n",
    "    \n",
    "    break '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
