{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel\n",
    "import nibabel.affines\n",
    "from PIL import Image\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import ants\n",
    "import scipy.io as sio\n",
    "import pickle\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import xmltodict\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File handling and loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image into nibabel\n",
    "def load_image(data_path, filename):\n",
    "    \n",
    "    return nibabel.load(f\"{data_path}/{filename}\")\n",
    "\n",
    "# Display the middle slice of a nibabel image\n",
    "def display_image(image):\n",
    "\n",
    "    # Get image data array from image object\n",
    "    image_array = np.asarray(image.dataobj)\n",
    "    \n",
    "    # Get middle slice\n",
    "    slice = image_array[image_array.shape[0] // 2, :, :]\n",
    "    \n",
    "    # Scale the image such that the maximum pixel value is 255\n",
    "    # Display the scaled image\n",
    "    display(Image.fromarray(((slice / np.max(slice)) * 255).astype(np.uint8)))\n",
    "    \n",
    "    return \n",
    "\n",
    "# Display the middle slice of a 3d array\n",
    "def display_array(array):\n",
    "    \n",
    "    # Get middle slice\n",
    "    slice = array[array.shape[0] // 2, :, :]\n",
    "    \n",
    "    # Scale the image such that the maximum pixel value is 255\n",
    "    # Display the scaled image\n",
    "    display(Image.fromarray(((slice / np.max(slice)) * 255).astype(np.uint8)))\n",
    "    \n",
    "    return \n",
    "\n",
    "# Find files with a specific filename and return a list. Non-recursive \n",
    "def list_files_ext(data_path, extensions):\n",
    "\n",
    "    files = [f for f in os.listdir(data_path) if f.endswith(extensions)]\n",
    "        \n",
    "    return files       \n",
    "\n",
    "# Return the absolute path to all files matching a filename in a directory. Recursive\n",
    "def list_files_fname(data_path, filename):\n",
    "    \n",
    "    matched_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        \n",
    "        for file in fnmatch.filter(files, filename):\n",
    "            \n",
    "            matched_files.append(os.path.join(root, file))\n",
    "    \n",
    "    return matched_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subject:\n",
    "    def __init__(self, path):\n",
    "        \n",
    "        self.path = path\n",
    "        \n",
    "        self.orig_nu = os.path.join(path, \"mri/orig_nu.mgz\")\n",
    "        \n",
    "        self.mask = os.path.join(path, \"mri/mask.mgz\")\n",
    "        \n",
    "        self.aparc = os.path.join(path, \"mri/aparc.DKTatlas+aseg.deep.mgz\")\n",
    "        \n",
    "        aligned_brain = os.path.join(path, \"aligned_brain.nii\")\n",
    "        \n",
    "        self.aligned_brain = aligned_brain if os.path.isfile(aligned_brain) else None\n",
    "        \n",
    "        aligned_cropped_brain = os.path.join(path, \"aligned_brain_cropped.nii\")\n",
    "        \n",
    "        self.aligned_cropped_brain = aligned_cropped_brain if os.path.isfile(aligned_cropped_brain) else None\n",
    "        \n",
    "        xml_files = glob.glob(os.path.join(path, \"*.xml\"))\n",
    "        \n",
    "        self.xml_path = xml_files[0] if xml_files else None\n",
    "        \n",
    "        # Load XML if file exists\n",
    "        if self.xml_path:\n",
    "            \n",
    "            with open(self.xml_path, 'r') as file:\n",
    "            \n",
    "                self.xml_df = xmltodict.parse(file.read())\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self.xml_df = None\n",
    "\n",
    "        \n",
    "        # Manually assign the column headers\n",
    "        header = ['ColHeaders', 'Index', 'SegId', 'NVoxels', 'Volume_mm3', 'StructName', 'normMean', 'normStdDev', 'normMin', 'normMax', 'normRange']\n",
    "        \n",
    "        self.aseg_stats = pd.read_csv(os.path.join(path, 'stats/aseg+DKT.stats'), delimiter='\\s+', comment='#', header=None, names=header)\n",
    "\n",
    "    def display_info(self):\n",
    "        \"\"\"Displays basic information about the subject\"\"\"\n",
    "        print(f\"Subject File Path: {self.file_path}\")\n",
    "        print(f\"DataFrame Head:\\n{self.aseg_stats.head()}\")\n",
    "        \n",
    "# Searches data_path for subject directories and creates an object for each of them\n",
    "def find_subjects(data_path):\n",
    "    \n",
    "    subject_list = []\n",
    "\n",
    "    for item in os.listdir(data_path):\n",
    "        \n",
    "        subject_path = os.path.join(data_path, item)\n",
    "        \n",
    "        if os.path.isdir(subject_path):\n",
    "            \n",
    "            # MRI directory of subject path (checking validity)\n",
    "            mri_path = os.path.join(subject_path, 'mri')\n",
    "            \n",
    "            # Check for MRI directory\n",
    "            if os.path.isdir(mri_path):\n",
    "                \n",
    "                orig_file = os.path.join(mri_path, 'orig_nu.mgz')\n",
    "                \n",
    "                mask_file = os.path.join(mri_path, 'mask.mgz')\n",
    "\n",
    "                # If both orig.mgz and mask.mgz exist, create object\n",
    "                if os.path.isfile(orig_file) and os.path.isfile(mask_file):\n",
    "                    \n",
    "                    subject_list.append(Subject(subject_path))\n",
    "\n",
    "    return subject_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image manipulation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs brain extraction using the orig_nu.mgz and mask.mgz of the subject by multiplying the mask with the image\n",
    "def extract_brain(orig_file, mask_file):\n",
    "    \n",
    "    # Load the image and the brain mask\n",
    "    image = nibabel.load(orig_file)\n",
    "    mask = nibabel.load(mask_file)\n",
    "    \n",
    "    # Get their image arrays\n",
    "    image_array = np.asarray(image.dataobj)\n",
    "    mask_array = np.asarray(mask.dataobj)\n",
    "    \n",
    "    # Apply the mask, the mask entries are 1 or 0\n",
    "    brain_array = image_array * mask_array\n",
    "    \n",
    "    return brain_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference brain (global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB seems that fastsrufer brain is better\n",
    "reference_brain_array_mni = extract_brain(\"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/mni_icbm152_lin_nifti/icbm_avg_152_t1_tal_lin.nii\", \"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/mni_icbm152_lin_nifti/icbm_avg_152_t1_tal_lin_mask.nii\")\n",
    "\n",
    "display_array(reference_brain_array_mni)\n",
    "\n",
    "reference_brain_array_fastsurfer = extract_brain(\"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/mni_icbm152_lin_nifti/fastsurfer-processed/mri/orig_nu.mgz\", \"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/mni_icbm152_lin_nifti/fastsurfer-processed/mri/mask.mgz\")\n",
    "\n",
    "display_array(reference_brain_array_fastsurfer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for affine registration and saving the transformation\n",
    "def affine_alignment(subject_list):\n",
    "        \n",
    "    # Use ProcessPoolExecutor to run affine alignment in parallel\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        \n",
    "        futures = []\n",
    "        \n",
    "        for subject in subject_list:\n",
    "\n",
    "            futures.append(executor.submit(alignment, subject))\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            \n",
    "            display_image(future.result())\n",
    "            \n",
    "    \n",
    "    def alignment(subject):\n",
    "        \n",
    "        # Extract brain of subject and convert it to an ANTsPy image\n",
    "        # The subject's brain is the moving image\n",
    "        brain_array = extract_brain(subject.orig, subject.mask)\n",
    "        \n",
    "        moving_image = ants.from_numpy(brain_array)\n",
    "        \n",
    "        # Convert the reference brain to an ANTsPy image\n",
    "        # The reference brain is already extracted\n",
    "        fixed_image = ants.from_numpy(reference_brain_array_fastsurfer)\n",
    "        \n",
    "        # Perform registration using ANTsPy\n",
    "        registration = ants.registration(fixed=fixed_image, moving=moving_image, type_of_transform='AffineFast')\n",
    "        \n",
    "        aligned_brain_array = registration['warpedmovout'].numpy()\n",
    "        \n",
    "        # Load the .mat file containing the transformation\n",
    "        transformation = sio.loadmat(registration['fwdtransforms'][0])\n",
    "        \n",
    "        # Save the transformation to a pickle file\n",
    "        with open(os.path.join(subject.path, 'affine_alignment.pkl'), 'wb') as file:\n",
    "            pickle.dump(transformation, file)\n",
    "        \n",
    "        # Make nibabel image from array\n",
    "        # Identity matrix as affine transform\n",
    "        aligned_image = nibabel.Nifti1Image(aligned_brain_array, np.eye(4))\n",
    "        \n",
    "        # Save the NiBabel image as a .nii file\n",
    "        aligned_image_path = os.path.join(subject.path, 'aligned_brain.nii')\n",
    "        \n",
    "        nibabel.save(aligned_image, aligned_image_path)\n",
    "        \n",
    "        subject.aligned_brain = aligned_image_path\n",
    "        \n",
    "        return aligned_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_subjects(subject_list):\n",
    "    \n",
    "    def bounding_box(image_array):\n",
    "    \n",
    "        non_zero_indices = np.nonzero(image_array)\n",
    "        \n",
    "        min_x, min_y, min_z = np.min(non_zero_indices[0]), np.min(non_zero_indices[1]), np.min(non_zero_indices[2])\n",
    "        max_x, max_y, max_z = np.max(non_zero_indices[0]), np.max(non_zero_indices[1]), np.max(non_zero_indices[2])\n",
    "        \n",
    "        return (min_x, min_y, min_z, max_x, max_y, max_z)\n",
    "    \n",
    "    max_bbox = (np.inf, np.inf, np.inf, -np.inf, -np.inf, -np.inf)\n",
    "    \n",
    "    # Find maximum bbox\n",
    "    for subject in subject_list:\n",
    "    \n",
    "        image = nibabel.load(os.path.join(subject.path, 'aligned_brain.nii'))\n",
    "        \n",
    "        min_x, min_y, min_z, max_x, max_y, max_z = bounding_box(image.get_fdata())\n",
    "        \n",
    "        global_min_x, global_min_y, global_min_z, global_max_x, global_max_y, global_max_z = max_bbox\n",
    "        \n",
    "        max_bbox = (\n",
    "            min(global_min_x, min_x),\n",
    "            min(global_min_y, min_y),\n",
    "            min(global_min_z, min_z),\n",
    "            max(global_max_x, max_x),\n",
    "            max(global_max_y, max_y),\n",
    "            max(global_max_z, max_z)\n",
    "        )\n",
    "    \n",
    "    # Crop the images\n",
    "    for subject in subject_list:\n",
    "        \n",
    "        image = nibabel.load(os.path.join(subject.path, 'aligned_brain.nii'))\n",
    "        \n",
    "        image_array = image.get_fdata()\n",
    "        \n",
    "        global_min_x, global_min_y, global_min_z, global_max_x, global_max_y, global_max_z = max_bbox\n",
    "        \n",
    "        # Crop the image array using the global bounding box\n",
    "        cropped_array = image_array[\n",
    "            int(global_min_x):int(global_max_x),\n",
    "            int(global_min_y):int(global_max_y),\n",
    "            int(global_min_z):int(global_max_z)\n",
    "        ]\n",
    "        \n",
    "        # Create a new NiBabel image from the cropped array\n",
    "        cropped_image = nibabel.Nifti1Image(cropped_array, image.affine)\n",
    "        \n",
    "        display_image(cropped_image)\n",
    "        \n",
    "        cropped_path = os.path.join(subject.path, 'aligned_brain_cropped.nii')\n",
    "        \n",
    "        # Overwrite the original image by saving the cropped image back to the same path\n",
    "        nibabel.save(cropped_image, cropped_path)\n",
    "        \n",
    "        subject.aligned_cropped_brain = cropped_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = find_subjects(\"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/scratch disk/full-datasets/adni1-complete-1yr-3t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subject_list:\n",
    "    \n",
    "    research_group = subject.xml_df['idaxs']['project']['subject']['researchGroup']\n",
    "    \n",
    "    print(research_group)\n",
    "    \n",
    "    display_image(nibabel.load(subject.aligned_cropped_brain))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nibabel import freesurfer\n",
    "\n",
    "aparc = nibabel.load(\"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/scratch disk/preprocess-sample/test-subject/mri/aparc.DKTatlas+aseg.deep.mgz\")\n",
    "\n",
    "\n",
    "\n",
    "print(aparc.header)\n",
    "\n",
    "\n",
    "annot = nibabel.freesurfer.read_annot(\"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/scratch disk/preprocess-sample/test-subject/mri/aparc.DKTatlas+aseg.deep.mgz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "- Crop images to reduce the size of 3d CNN (could crop to the boundaries of the max brain after registration)\n",
    "- Load XML disease label and store with image. NB could implement a class that stores various image data\n",
    "- Start training NN\n",
    "\n",
    "NB no need for intensity normalisation this is already done by freesurfer/fastsurfer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
