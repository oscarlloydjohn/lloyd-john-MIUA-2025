{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel\n",
    "import nibabel.affines\n",
    "from PIL import Image\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import ants\n",
    "import scipy.io as sio\n",
    "import pickle\n",
    "import concurrent.futures\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File handling and loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image into nibabel\n",
    "def load_image(data_path, filename):\n",
    "    \n",
    "    return nibabel.load(f\"{data_path}/{filename}\")\n",
    "\n",
    "# Display the middle slice of a nibabel image\n",
    "def display_image(image):\n",
    "\n",
    "    # Get image data array from image object\n",
    "    image_array = np.asarray(image.dataobj)\n",
    "    \n",
    "    # Get middle slice\n",
    "    slice = image_array[image_array.shape[0] // 2, :, :]\n",
    "    \n",
    "    # Scale the image such that the maximum pixel value is 255\n",
    "    # Display the scaled image\n",
    "    display(Image.fromarray(((slice / np.max(slice)) * 255).astype(np.uint8)))\n",
    "    \n",
    "    return \n",
    "\n",
    "# Display the middle slice of a 3d array\n",
    "def display_array(array):\n",
    "    \n",
    "    # Get middle slice\n",
    "    slice = array[array.shape[0] // 2, :, :]\n",
    "    \n",
    "    # Scale the image such that the maximum pixel value is 255\n",
    "    # Display the scaled image\n",
    "    display(Image.fromarray(((slice / np.max(slice)) * 255).astype(np.uint8)))\n",
    "    \n",
    "    return \n",
    "\n",
    "# Find files with a specific filename and return a list. Non-recursive \n",
    "def list_files_ext(data_path, extensions):\n",
    "\n",
    "    files = [f for f in os.listdir(data_path) if f.endswith(extensions)]\n",
    "        \n",
    "    return files       \n",
    "\n",
    "# Return the absolute path to all files matching a filename in a directory. Recursive\n",
    "def list_files_fname(data_path, filename):\n",
    "    \n",
    "    matched_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        \n",
    "        for file in fnmatch.filter(files, filename):\n",
    "            \n",
    "            matched_files.append(os.path.join(root, file))\n",
    "    \n",
    "    return matched_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image manipulation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dictionary of subjects with their orig_nu.mgz, mask.mgz, and subj_dir paths\n",
    "def get_dict(data_path):\n",
    "    \n",
    "    dict = {}\n",
    "\n",
    "    for item in os.listdir(data_path):\n",
    "        \n",
    "        subject_path = os.path.join(data_path, item)\n",
    "        \n",
    "        if os.path.isdir(subject_path):\n",
    "            \n",
    "            # MRI directory of subject path\n",
    "            mri_path = os.path.join(subject_path, 'mri')\n",
    "            \n",
    "            # Check for MRI directory\n",
    "            if os.path.isdir(mri_path):\n",
    "                \n",
    "                orig_file = os.path.join(mri_path, 'orig_nu.mgz')\n",
    "                \n",
    "                mask_file = os.path.join(mri_path, 'mask.mgz')\n",
    "\n",
    "                # If both orig.mgz and mask.mgz exist, add them to the dictionary\n",
    "                if os.path.isfile(orig_file) and os.path.isfile(mask_file):\n",
    "                    \n",
    "                    dict[item] = {'orig': orig_file, 'mask': mask_file, 'subj_dir': subject_path}\n",
    "\n",
    "    return dict\n",
    "\n",
    "# Performs brain extraction using the orig_nu.mgz and mask.mgz of the subject by multiplying the mask with the image\n",
    "def extract_brain(orig_file, mask_file):\n",
    "    \n",
    "    # Load the image and the brain mask\n",
    "    image = nibabel.load(orig_file)\n",
    "    mask = nibabel.load(mask_file)\n",
    "    \n",
    "    # Get their image arrays\n",
    "    image_array = np.asarray(image.dataobj)\n",
    "    mask_array = np.asarray(mask.dataobj)\n",
    "    \n",
    "    # Apply the mask, the mask entries are 1 or 0\n",
    "    brain_array = image_array * mask_array\n",
    "    \n",
    "    return brain_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference brain (global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB seems that fastsrufer brain is better\n",
    "reference_brain_array_mni = extract_brain(\"mni_icbm152_lin_nifti/icbm_avg_152_t1_tal_lin.nii\", \"mni_icbm152_lin_nifti/icbm_avg_152_t1_tal_lin_mask.nii\")\n",
    "\n",
    "display_array(reference_brain_array_mni)\n",
    "\n",
    "reference_brain_array_fastsurfer = extract_brain(\"mni_icbm152_lin_nifti/fastsurfer-processed/mri/orig_nu.mgz\", \"mni_icbm152_lin_nifti/fastsurfer-processed/mri/mask.mgz\")\n",
    "\n",
    "display_array(reference_brain_array_fastsurfer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for affine registration and saving the transformation\n",
    "def affine_alignment(subject_data):\n",
    "\n",
    "    # Extract brain of subject and convert it to an ANTsPy image\n",
    "    # The subject's brain is the moving image\n",
    "    brain_array = extract_brain(subject_data['orig'], subject_data['mask'])\n",
    "    \n",
    "    moving_image = ants.from_numpy(brain_array)\n",
    "    \n",
    "    # Convert the reference brain to an ANTsPy image\n",
    "    # The reference brain is already extracted\n",
    "    fixed_image = ants.from_numpy(reference_brain_array_fastsurfer)\n",
    "    \n",
    "    # Perform registration using ANTsPy\n",
    "    registration = ants.registration(fixed=fixed_image, moving=moving_image, type_of_transform='AffineFast')\n",
    "    \n",
    "    aligned_brain_array = registration['warpedmovout'].numpy()\n",
    "    \n",
    "    # Load the .mat file containing the transformation\n",
    "    transformation = sio.loadmat(registration['fwdtransforms'][0])\n",
    "    \n",
    "    # Save the transformation to a pickle file\n",
    "    with open(os.path.join(subject_data['subj_dir'], 'affine_alignment.pkl'), 'wb') as file:\n",
    "        pickle.dump(transformation, file)\n",
    "    \n",
    "    # Make nibabel image from array\n",
    "    # Identity matrix as affine transform\n",
    "    aligned_image = nibabel.Nifti1Image(aligned_brain_array, np.eye(4))\n",
    "    \n",
    "    # Save the NiBabel image as a .nii file\n",
    "    aligned_image_path = os.path.join(subject_data['subj_dir'], 'aligned_brain.nii')\n",
    "    \n",
    "    nibabel.save(aligned_image, aligned_image_path)\n",
    "    \n",
    "    return aligned_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box(image_array):\n",
    "    \n",
    "    non_zero_indices = np.nonzero(image_array)\n",
    "    \n",
    "    min_x, min_y, min_z = np.min(non_zero_indices[0]), np.min(non_zero_indices[1]), np.min(non_zero_indices[2])\n",
    "    max_x, max_y, max_z = np.max(non_zero_indices[0]), np.max(non_zero_indices[1]), np.max(non_zero_indices[2])\n",
    "    \n",
    "    return (min_x, min_y, min_z, max_x, max_y, max_z)\n",
    "\n",
    "def crop_array(image_array, bounding_box, border_size=2):\n",
    "\n",
    "    min_x, min_y, min_z, max_x, max_y, max_z = bounding_box\n",
    "    \n",
    "    min_x = max(min_x - border_size, 0)\n",
    "    min_y = max(min_y - border_size, 0)\n",
    "    min_z = max(min_z - border_size, 0)\n",
    "    \n",
    "    max_x = min(max_x + border_size, image_array.shape[0] - 1)\n",
    "    max_y = min(max_y + border_size, image_array.shape[1] - 1)\n",
    "    max_z = min(max_z + border_size, image_array.shape[2] - 1)\n",
    "    \n",
    "    return image_array[min_x:max_x+1, min_y:max_y+1, min_z:max_z+1]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/scratch disk/preprocess-sample\"\n",
    "\n",
    "# List of masks\n",
    "fpath_list = list_files_fname(data_path, \"mask.mgz\")\n",
    "\n",
    "# Number of masks\n",
    "print(f\"{len(fpath_list)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_dict = get_dict(data_path)\n",
    "    \n",
    "# Use ProcessPoolExecutor to run affine alignment in parallel\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    \n",
    "    futures = []\n",
    "    \n",
    "    for subject_key, subject_data in subj_dict.items():\n",
    "\n",
    "        futures.append(executor.submit(affine_alignment, subject_data))\n",
    "    \n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        \n",
    "        display_image(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_dict = get_dict(data_path)\n",
    "\n",
    "max_bbox = (np.inf, np.inf, np.inf, -np.inf, -np.inf, -np.inf)\n",
    "\n",
    "for subject_key, subject_data in subj_dict.items():\n",
    "    \n",
    "    image = nibabel.load(os.path.join(subject_data['subj_dir'], 'aligned_brain.nii'))\n",
    "    \n",
    "    min_x, min_y, min_z, max_x, max_y, max_z = bounding_box(image.get_fdata())\n",
    "    \n",
    "    global_min_x, global_min_y, global_min_z, global_max_x, global_max_y, global_max_z = max_bbox\n",
    "    \n",
    "    max_bbox = (\n",
    "        min(global_min_x, min_x),\n",
    "        min(global_min_y, min_y),\n",
    "        min(global_min_z, min_z),\n",
    "        max(global_max_x, max_x),\n",
    "        max(global_max_y, max_y),\n",
    "        max(global_max_z, max_z)\n",
    "    )\n",
    "    \n",
    "    print(max_bbox)\n",
    "    \n",
    "print(max_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject_key, subject_data in subj_dict.items():\n",
    "    \n",
    "    image = nibabel.load(os.path.join(subject_data['subj_dir'], 'aligned_brain.nii'))\n",
    "    \n",
    "    image_array = image.get_fdata()\n",
    "    \n",
    "    global_min_x, global_min_y, global_min_z, global_max_x, global_max_y, global_max_z = max_bbox\n",
    "    \n",
    "    # Crop the image array using the global bounding box\n",
    "    cropped_array = image_array[\n",
    "        int(global_min_x):int(global_max_x),\n",
    "        int(global_min_y):int(global_max_y),\n",
    "        int(global_min_z):int(global_max_z)\n",
    "    ]\n",
    "    \n",
    "    # Create a new NiBabel image from the cropped array\n",
    "    cropped_image = nibabel.Nifti1Image(cropped_array, image.affine)\n",
    "    \n",
    "    display_image(cropped_image)\n",
    "    \n",
    "    # Overwrite the original image by saving the cropped image back to the same path\n",
    "    nibabel.save(cropped_image, os.path.join(subject_data['subj_dir'], 'aligned_brain_cropped.nii'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "- Crop images to reduce the size of 3d CNN (could crop to the boundaries of the max brain after registration)\n",
    "- Load XML disease label and store with image. NB could implement a class that stores various image data\n",
    "- Start training NN\n",
    "\n",
    "NB no need for intensity normalisation this is already done by freesurfer/fastsurfer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
