{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torcheval.metrics import *\n",
    "\n",
    "# Benny pointnet\n",
    "from pointnet2_benny import pointnet2_cls_msg\n",
    "import cnn3d_xmuyzz.ResNetV2\n",
    "\n",
    "import dill as pickle\n",
    "from captum.attr import *\n",
    "import pyvista as pv\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "# Custom modules\n",
    "from preprocessing_post_fastsurfer.subject import *\n",
    "from preprocessing_post_fastsurfer.vis import *\n",
    "from ozzy_torch_utils.split_dataset import *\n",
    "from ozzy_torch_utils.subject_dataset import *\n",
    "from ozzy_torch_utils.plot import *\n",
    "from ozzy_torch_utils.train_nn import *\n",
    "from ozzy_torch_utils.model_parameters import *\n",
    "from ozzy_torch_utils.init_dataloaders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_pathname = \"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/runs/run_18-03-2025_15-35-05/run_18-03-2025_15-35-05_params.pkl\"\n",
    "\n",
    "with open(pickle_pathname, 'rb') as file:\n",
    "    \n",
    "    model_parameters = pickle.load(file)\n",
    "    \n",
    "model = model_parameters.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 4.38210990e-04  4.35401486e-05  1.73917944e-04]\n",
      " [ 1.41161117e-03  3.66886599e-04 -5.28144886e-04]\n",
      " ...\n",
      " [-6.31989606e-08  6.93569890e-08  2.24684138e-09]\n",
      " [-2.66994427e-02  1.06173153e-02 -2.25369260e-02]\n",
      " [-4.66896703e-03  5.77828330e-03 -8.89809744e-03]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    # Wrap model as pointnet_cls outputs a tuple for some reason\n",
    "    wrapped_model = lambda x: model(x)[0]\n",
    "\n",
    "    ig = IntegratedGradients(wrapped_model)\n",
    "    \n",
    "    # Example data\n",
    "    cloud = np.load(\"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/scratch-disk/full-datasets/hcampus-1.5T-cohort/ADNI_002_S_0413_MR_MPR-R__GradWarp__B1_Correction_Br_20070319120315662_S13894_I45122/Left-Hippocampus_aligned_cropped_mesh_downsampledcloud.npy\")\n",
    "\n",
    "    input = torch.from_numpy(cloud)\n",
    "\n",
    "    # NN expects float32 on cuda\n",
    "    input = input.type(torch.float32).to('cuda')\n",
    "\n",
    "    # Unsqueeze to add empty batch dimension then transpose  to 3 x n as expected by pointnet\n",
    "    input = input.unsqueeze(0).transpose(2, 1)\n",
    "\n",
    "    # Baseline is zeros, however could also be some kind of noise cloud\n",
    "    baseline = torch.zeros_like(input)\n",
    "\n",
    "    attributions = ig.attribute(input, baseline, target=1, internal_batch_size=1)\n",
    "    \n",
    "    # Transpose back to n x 3 and remove batch dim\n",
    "    attributions = attributions.transpose(1, 2).squeeze(0)\n",
    "    \n",
    "    # Move to CPU for processing\n",
    "    attributions = attributions.cpu().numpy()\n",
    "    \n",
    "    print(attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281dcc4fbf9149caa4a52fcfca051c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:44215/index.html?ui=P_0x7fe66e9275f0_13&reconnect=auto\" class=\"pyvâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sum x, y and z values for an overall attribution for that point\n",
    "xyz_sum = np.sum(attributions, axis=1)\n",
    "\n",
    "xyz_sum = np.sign(xyz_sum) * np.power(np.abs(xyz_sum), 0.1)\n",
    "\n",
    "# Normalise into range -1, 1 such that positive and negative attributions are preserved\n",
    "\n",
    "norm = Normalize(vmin = -np.max(np.abs(xyz_sum)), vmax = np.max(np.abs(xyz_sum)))\n",
    "\n",
    "norm_attributions = norm(xyz_sum)\n",
    "\n",
    "# Cmap for pyvista\n",
    "cmap = plt.get_cmap('seismic')\n",
    "colours = cmap(norm_attributions)\n",
    "colours_rgb = (colours[:, :3] * 255).astype(np.uint8)\n",
    "\n",
    "pv_cloud = pv.PolyData(cloud)\n",
    "\n",
    "pv_cloud['colors'] = colours_rgb\n",
    "    \n",
    "plotter = pv.Plotter()\n",
    "\n",
    "plotter.add_points(pv_cloud, scalars='colors', rgb=True)\n",
    "\n",
    "plotter.set_background(\"black\")\n",
    "\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
