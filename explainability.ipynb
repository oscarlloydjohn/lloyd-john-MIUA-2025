{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torcheval.metrics import *\n",
    "\n",
    "import pickle\n",
    "from captum.attr import *\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Custom modules\n",
    "from preprocessing_post_fastsurfer.subject import *\n",
    "from preprocessing_post_fastsurfer.vis import *\n",
    "from ozzy_torch_utils.split_dataset import *\n",
    "from ozzy_torch_utils.subject_dataset import *\n",
    "from ozzy_torch_utils.plot import *\n",
    "from ozzy_torch_utils.train_nn import *\n",
    "from ozzy_torch_utils.model_parameters import *\n",
    "from ozzy_torch_utils.init_dataloaders import *\n",
    "from explain_pointnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "pickle_pathname = \"/uolstore/home/student_lnxhome01/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/runs/run_18-03-2025_15-35-05/run_18-03-2025_15-35-05_params.pkl\"\n",
    "\n",
    "with open(pickle_pathname, 'rb') as file:\n",
    "    \n",
    "    model_parameters = pickle.load(file)\n",
    "    \n",
    "model = model_parameters.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_path = \"/uolstore/home/users/sc22olj/Compsci/year3/individual-project-COMP3931/individual-project-sc22olj/scratch-disk/full-datasets/hcampus-1.5T-cohort\"\n",
    "\n",
    "subject_list = find_subjects_parallel(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting experiment comparing attributions from two permutations of the same cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = sample(subject_list, 1)[0]\n",
    "\n",
    "cloud = np.load(os.path.join(subject.path, \"Left-Hippocampus_aligned_cropped_mesh_downsampledcloud.npy\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.65154829e-08 1.01864301e-07 2.99499747e-07]\n",
      " [1.47840784e-02 4.18064712e-02 2.85079568e-02]\n",
      " [7.34231075e-13 3.12145172e-13 6.60628809e-13]\n",
      " ...\n",
      " [1.33077205e-07 6.12107915e-09 2.18990218e-07]\n",
      " [1.14355741e-10 7.65692545e-12 4.75774655e-12]\n",
      " [1.41251399e-06 2.98809966e-06 2.19691583e-06]]\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "\n",
    "attributions_orig, pred_research_group_orig = pointnet_ig(model, cloud, device)\n",
    "\n",
    "shuffler = np.random.permutation(cloud.shape[0])\n",
    "\n",
    "unshuffler = np.argsort(shuffler)\n",
    "\n",
    "cloud_shuffled = np.array(cloud[i] for i in shuffler)\n",
    "\n",
    "attributions_shuffled, pred_research_group_shuffle = pointnet_ig(model, cloud_shuffled, device)\n",
    "\n",
    "cloud_unshuffled = [cloud_shuffled[i] for i in unshuffler]\n",
    "\n",
    "attributions_unshuffled = np.array([attributions_shuffled[i] for i in unshuffler])\n",
    "\n",
    "attributions_diff = attributions_orig - attributions_unshuffled\n",
    "\n",
    "print(attributions_diff)\n",
    "\n",
    "if pred_research_group_orig != pred_research_group_shuffle:\n",
    "    \n",
    "    print(\"Research groups are different after shuffle\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_attributions(attributions, subject, cloud, pred_research_group):\n",
    "    \n",
    "    # Sum x, y and z values for an overall attribution for that point\n",
    "    xyz_sum = np.sum(attributions, axis=1)\n",
    "\n",
    "    xyz_sum = np.sign(xyz_sum) * np.power(np.abs(xyz_sum), 0.1)\n",
    "\n",
    "    # Normalise into range -1, 1 such that positive and negative attributions are preserved\n",
    "    norm = Normalize(vmin = -np.max(np.abs(xyz_sum)), vmax = np.max(np.abs(xyz_sum)))\n",
    "\n",
    "    norm_attributions = norm(xyz_sum)\n",
    "\n",
    "    # Cmap for pyvista\n",
    "    cmap = plt.get_cmap('seismic')\n",
    "    colours = cmap(norm_attributions)\n",
    "\n",
    "    pv_cloud = pv.PolyData(cloud)\n",
    "\n",
    "    plotter = pv.Plotter()\n",
    "\n",
    "    plotter.add_points(pv_cloud, scalars=colours, rgb=True)\n",
    "\n",
    "    plotter.set_background(\"black\")\n",
    "\n",
    "    # THIS IS NOT FOR USE, IT IS RUNNING PREDICTIONS ON TRAINING DATA!!\n",
    "    plotter.add_text(\"This is just a test running on training data!\", color='white')\n",
    "    plotter.add_text(f\"True class: {str(subject.subject_metadata['Group'].iloc[0])} \\n Predicted class: {pred_research_group} \", color='white', position='upper_right')\n",
    "\n",
    "    plotter.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ca1d3f63a44e9ea8a40dad0336e9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:34717/index.html?ui=P_0x7f27091ba3f0_0&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f15352011f4de6920e7b86da4ca4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:34717/index.html?ui=P_0x7f27081d9ac0_1&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21d5c90447146de9f4188a1397d16ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:34717/index.html?ui=P_0x7f2701d98f80_2&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_attributions(attributions_orig, subject, cloud, pred_research_group_orig)\n",
    "\n",
    "#vis_attributions(attributions_unshuffle, subject, cloud, pred_research_group_shuffle)\n",
    "\n",
    "#vis_attributions(attributions_diff, subject, cloud, pred_research_group_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
